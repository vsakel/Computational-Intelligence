{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_tuner"
      ],
      "metadata": {
        "id": "nSbh0D47d_GL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imports \n",
        "# always run this cell\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from keras import backend as K\n",
        "import keras_tuner as kt\n",
        "from sklearn.metrics import confusion_matrix, classification_report, multilabel_confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "JzLjGvobcr8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the MNIST dataset\n",
        "\n",
        "(Xtrain, ytrain), (Xtest, ytest) = mnist.load_data()\n",
        "\n",
        "# scale the data in range [0,1]\n",
        "Xtrain = Xtrain.astype('float32') / 255.0\n",
        "Xtest = Xtest.astype('float32') / 255.0\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "# we need to one hot encoding the target values, to help the training process of neural network\n",
        "# we will use cross entropy loss function so we must represent the target values as one hot encoding vectors according to keras documentation\n",
        "ytrain_onehot = keras.utils.to_categorical(ytrain,num_classes)\n",
        "ytest_onehot = keras.utils.to_categorical(ytest,num_classes)\n",
        "\n"
      ],
      "metadata": {
        "id": "lzGaOxf153j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters tuning using grid search with 5 fold cross validation\n",
        "# IT TAKES SO LONG TO RUN\n",
        "# SO WE WILL USE KERAS TUNER Hyperband for hyperparameters tuning as we see in class\n",
        "\n",
        "# need these custom functions to compute f1_score\n",
        "def recall(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    all_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    \n",
        "    recall = true_positives / (all_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision(y_true, y_pred): \n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    precision_score = precision(y_true, y_pred)\n",
        "    recall_score = recall(y_true, y_pred)\n",
        "    return 2*((precision_score*recall_score)/(precision_score+recall_score+K.epsilon()))\n",
        "\n",
        "\n",
        "def model_builder(hp):\n",
        "    #define hyperparameters\n",
        "    hp_n1=hp.Choice('n1', values=[64, 128])\n",
        "    hp_n2=hp.Choice('n2', values=[256, 512])\n",
        "    hp_a=hp.Choice('a', values=[0.1, 0.001, 0.000001])\n",
        "    hp_lr=hp.Choice('learning_rate', values=[0.1, 0.01, 0.001])\n",
        "\n",
        "    # define the general model\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=(28, 28)))\n",
        "    model.add(Dense(hp_n1, activation='relu',kernel_initializer='he_normal', kernel_regularizer=keras.regularizers.l2(hp_a))) # hidden layer 1 fully connected\n",
        "    model.add(Dense(hp_n2, activation='relu',kernel_initializer='he_normal', kernel_regularizer=keras.regularizers.l2(hp_a))) # hidden layer 2 fully connected\n",
        "    model.add(Dense(10, activation='softmax',kernel_initializer='he_normal', kernel_regularizer=keras.regularizers.l2(hp_a))) # output layer\n",
        "    model.compile(loss=keras.losses.CategoricalCrossentropy(), optimizer = keras.optimizers.RMSprop(learning_rate=hp_lr), metrics=['accuracy', f1])\n",
        "    return model\n",
        "\n",
        "\n",
        "#Using Hyperband \n",
        "tuner = kt.Hyperband(model_builder, objective=kt.Objective('val_f1', direction = 'max'),max_epochs=1000)\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=200)\n",
        "tuner.search(Xtrain, ytrain_onehot, epochs=1000, validation_split=0.2, callbacks=[early_stop])\n",
        "# get the best model\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(\"best models hyperparameters : n1=%d n2=%d a=%f learning_rate=%f\" % (best_hps.get('n1'), best_hps.get('n2'), best_hps.get('a'), best_hps.get('learning_rate')))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Grid search\n",
        "# # grid search parameters\n",
        "# nh1 = [64, 128] # number of neurons in hidden layer1\n",
        "# nh2 = [256, 512] # number of neurons in hidden layer2\n",
        "# a_l2 = [0.1, 0.001, 0.000001] # a parameter for l2 regularization\n",
        "# learning_rate = [0.1, 0.01, 0.001] # learning rate in rmsprop optimizer\n",
        "\n",
        "# earlystop = keras.callbacks.EarlyStopping(monitor='val_f1', patience=200) # define early stopping to help the training process of mlp\n",
        "# f1_mean = [] # store the f1_mean of every model \n",
        "# accuracy_mean = [] # store accuracy mean of every model\n",
        "# precision_mean = []\n",
        "# recall_mean = []\n",
        "# hyperparameters = [] # store the hyperparameters, every row corresponds to a model and a f1_mean value\n",
        "\n",
        "#cv = KFold(n_splits=5)\n",
        "\n",
        "# for n1 in nh1:\n",
        "#   for n2 in nh2:\n",
        "#     for a in a_l2:\n",
        "#       for lr in learning_rate:\n",
        "#         f1_score = []\n",
        "#         accuracy = []\n",
        "#         precision_score = []\n",
        "#         recall_score = []\n",
        "#         for train_indices, test_indices in cv.split(Xtrain):\n",
        "#           # define the train and test data for every iteration of cross validation \n",
        "#           x_train, x_test = Xtrain[train_indices], Xtrain[test_indices]\n",
        "#           y_train, y_test = ytrain_onehot[train_indices], ytrain_onehot[test_indices]\n",
        "#           # define the model we test\n",
        "#           model = Sequential()\n",
        "#           model.add(Flatten(input_shape=(28, 28)))\n",
        "#           model.add(Dense(n1, activation='relu',kernel_initializer='he_normal', kernel_regularizer=keras.regularizers.l2(a))) # hidden layer 1 fully connected\n",
        "#           model.add(Dense(n2, activation='relu',kernel_initializer='he_normal', kernel_regularizer=keras.regularizers.l2(a))) # hidden layer 2 fully connected\n",
        "#           model.add(Dense(10, activation='softmax',kernel_initializer='he_normal', kernel_regularizer=keras.regularizers.l2(a))) # output layer\n",
        "#           model.compile(loss=keras.losses.CategoricalCrossentropy(), optimizer = keras.optimizers.RMSprop(learning_rate=lr), metrics=['accuracy', f1, precision, recall])\n",
        "#           history = model.fit(x_train,y_train, batch_size = 256, epochs = 1000, validation_data = (x_test,y_test), callbacks = [earlystop]) \n",
        "#           f1_score.append(max(history.history['val_f1']))\n",
        "#           accuracy.append(max(history.history['val_accuracy']))\n",
        "#           recall_score.append(max(history.history['val_recall']))\n",
        "#           precision_score.append(max(history.history['val_precision']))\n",
        "  \n",
        "#         f1_mean.append(np.mean(f1_score))\n",
        "#         accuracy_mean.append(np.mean(accuracy))\n",
        "#         recall_mean.append(np.mean(recall_score))\n",
        "#         precision_mean.append(np.mean(precision_score))\n",
        "#         hyperparameters.append((n1,n2,a,lr))\n",
        "\n",
        "# max_index = np.argmax(f1_mean)\n",
        "# print(f1_mean)\n",
        "# print(accuracy_mean)\n",
        "# print(precision_mean)\n",
        "# print(recall_mean)\n",
        "# print(\"best model F-score is: \",f1_mean[max_index])\n",
        "# print(\"Hyperparameters of best model: nh1 = \"+str(hyperparameters[max_index][0])+\", nh2 = \"+str(hyperparameters[max_index][1])+\", a = \"+str(hyperparameters[max_index][2])+\", lr = \"+str(hyperparameters[max_index][3]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drnIPsG1dp0n",
        "outputId": "421b18e7-daaf-475c-e396-e2e3dff407b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 Complete [00h 00m 11s]\n",
            "val_f1: 0.0\n",
            "\n",
            "Best val_f1 So Far: 0.9678891897201538\n",
            "Total elapsed time: 00h 07m 03s\n",
            "best models hyperparameters : n1=128 n2=512 a=0.000001 learning_rate=0.001000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# best model\n",
        "# find optimal number of epochs for which to train best model \n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(Xtrain, ytrain_onehot,batch_size=256, epochs=1000, validation_split=0.2)\n",
        "val_f1_per_epoch = history.history['val_accuracy']\n",
        "best_epoch = val_f1_per_epoch.index(max(val_f1_per_epoch)) + 1\n",
        "print(\"The optimal number of epochs is\", best_epoch)\n",
        "\n",
        "# we retrain the best model for optimal number of epochs \n",
        "hypermodel = tuner.hypermodel.build(best_hps)\n",
        "history = hypermodel.fit(Xtrain, ytrain_onehot, batch_size=256, epochs=best_epoch, validation_split=0.2)\n",
        "\n",
        "# plot accuracy \n",
        "plt.figure() \n",
        "plt.title('Classification Accuracy')\n",
        "plt.plot(history.history['val_accuracy'],color='orange',label='validation')\n",
        "plt.plot(history.history['accuracy'],color='blue',label='train')\n",
        "plt.xlabel('# of epochs')\n",
        "plt.legend(['val_accuracy', 'accuracy'])\n",
        "# plot learning curve\n",
        "plt.figure()\n",
        "plt.title('Loss')\n",
        "plt.plot(history.history['val_loss'],color='orange',label='validation')\n",
        "plt.plot(history.history['loss'],color='blue',label='train')\n",
        "plt.xlabel('# of epochs')\n",
        "plt.legend(['val_loss', 'loss'])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lfVWijLbxYw2",
        "outputId": "0ab7e1f1-2987-4c6f-8971-8fb42f5bc241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.3611 - accuracy: 0.8935 - f1: 0.8803 - val_loss: 0.2020 - val_accuracy: 0.9419 - val_f1: 0.9434\n",
            "Epoch 2/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.1504 - accuracy: 0.9558 - f1: 0.9563 - val_loss: 0.1896 - val_accuracy: 0.9404 - val_f1: 0.9400\n",
            "Epoch 3/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.1040 - accuracy: 0.9685 - f1: 0.9689 - val_loss: 0.1145 - val_accuracy: 0.9659 - val_f1: 0.9666\n",
            "Epoch 4/1000\n",
            "188/188 [==============================] - 4s 19ms/step - loss: 0.0762 - accuracy: 0.9764 - f1: 0.9768 - val_loss: 0.1020 - val_accuracy: 0.9694 - val_f1: 0.9705\n",
            "Epoch 5/1000\n",
            "188/188 [==============================] - 4s 23ms/step - loss: 0.0597 - accuracy: 0.9821 - f1: 0.9822 - val_loss: 0.0882 - val_accuracy: 0.9749 - val_f1: 0.9749\n",
            "Epoch 6/1000\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0471 - accuracy: 0.9859 - f1: 0.9861 - val_loss: 0.1110 - val_accuracy: 0.9686 - val_f1: 0.9692\n",
            "Epoch 7/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0378 - accuracy: 0.9889 - f1: 0.9888 - val_loss: 0.0968 - val_accuracy: 0.9718 - val_f1: 0.9721\n",
            "Epoch 8/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0303 - accuracy: 0.9911 - f1: 0.9912 - val_loss: 0.1221 - val_accuracy: 0.9684 - val_f1: 0.9687\n",
            "Epoch 9/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0253 - accuracy: 0.9929 - f1: 0.9929 - val_loss: 0.0964 - val_accuracy: 0.9762 - val_f1: 0.9764\n",
            "Epoch 10/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0207 - accuracy: 0.9942 - f1: 0.9941 - val_loss: 0.1038 - val_accuracy: 0.9735 - val_f1: 0.9734\n",
            "Epoch 11/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0167 - accuracy: 0.9956 - f1: 0.9956 - val_loss: 0.1000 - val_accuracy: 0.9766 - val_f1: 0.9770\n",
            "Epoch 12/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0133 - accuracy: 0.9966 - f1: 0.9967 - val_loss: 0.1242 - val_accuracy: 0.9722 - val_f1: 0.9723\n",
            "Epoch 13/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0134 - accuracy: 0.9960 - f1: 0.9960 - val_loss: 0.1036 - val_accuracy: 0.9772 - val_f1: 0.9775\n",
            "Epoch 14/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0108 - accuracy: 0.9973 - f1: 0.9973 - val_loss: 0.1167 - val_accuracy: 0.9737 - val_f1: 0.9739\n",
            "Epoch 15/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0087 - accuracy: 0.9979 - f1: 0.9979 - val_loss: 0.1230 - val_accuracy: 0.9771 - val_f1: 0.9770\n",
            "Epoch 16/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0088 - accuracy: 0.9977 - f1: 0.9976 - val_loss: 0.1199 - val_accuracy: 0.9754 - val_f1: 0.9753\n",
            "Epoch 17/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0071 - accuracy: 0.9984 - f1: 0.9984 - val_loss: 0.1157 - val_accuracy: 0.9781 - val_f1: 0.9782\n",
            "Epoch 18/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0072 - accuracy: 0.9984 - f1: 0.9984 - val_loss: 0.1257 - val_accuracy: 0.9772 - val_f1: 0.9772\n",
            "Epoch 19/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0068 - accuracy: 0.9986 - f1: 0.9986 - val_loss: 0.1203 - val_accuracy: 0.9787 - val_f1: 0.9790\n",
            "Epoch 20/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0061 - accuracy: 0.9989 - f1: 0.9989 - val_loss: 0.1214 - val_accuracy: 0.9797 - val_f1: 0.9799\n",
            "Epoch 21/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0057 - accuracy: 0.9988 - f1: 0.9988 - val_loss: 0.1430 - val_accuracy: 0.9765 - val_f1: 0.9766\n",
            "Epoch 22/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0057 - accuracy: 0.9989 - f1: 0.9989 - val_loss: 0.1375 - val_accuracy: 0.9759 - val_f1: 0.9762\n",
            "Epoch 23/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0057 - accuracy: 0.9989 - f1: 0.9989 - val_loss: 0.1552 - val_accuracy: 0.9752 - val_f1: 0.9753\n",
            "Epoch 24/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0058 - accuracy: 0.9987 - f1: 0.9987 - val_loss: 0.1329 - val_accuracy: 0.9784 - val_f1: 0.9787\n",
            "Epoch 25/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0047 - accuracy: 0.9991 - f1: 0.9991 - val_loss: 0.1377 - val_accuracy: 0.9779 - val_f1: 0.9781\n",
            "Epoch 26/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0048 - accuracy: 0.9990 - f1: 0.9990 - val_loss: 0.1444 - val_accuracy: 0.9778 - val_f1: 0.9778\n",
            "Epoch 27/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0046 - accuracy: 0.9992 - f1: 0.9992 - val_loss: 0.1684 - val_accuracy: 0.9742 - val_f1: 0.9744\n",
            "Epoch 28/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0048 - accuracy: 0.9991 - f1: 0.9991 - val_loss: 0.1473 - val_accuracy: 0.9778 - val_f1: 0.9778\n",
            "Epoch 29/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0045 - accuracy: 0.9991 - f1: 0.9991 - val_loss: 0.1421 - val_accuracy: 0.9786 - val_f1: 0.9788\n",
            "Epoch 30/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0045 - accuracy: 0.9992 - f1: 0.9992 - val_loss: 0.1571 - val_accuracy: 0.9779 - val_f1: 0.9780\n",
            "Epoch 31/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0043 - accuracy: 0.9993 - f1: 0.9993 - val_loss: 0.1513 - val_accuracy: 0.9764 - val_f1: 0.9765\n",
            "Epoch 32/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0052 - accuracy: 0.9989 - f1: 0.9989 - val_loss: 0.1385 - val_accuracy: 0.9798 - val_f1: 0.9798\n",
            "Epoch 33/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0043 - accuracy: 0.9993 - f1: 0.9993 - val_loss: 0.1613 - val_accuracy: 0.9778 - val_f1: 0.9778\n",
            "Epoch 34/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0045 - accuracy: 0.9993 - f1: 0.9993 - val_loss: 0.1508 - val_accuracy: 0.9774 - val_f1: 0.9774\n",
            "Epoch 35/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0041 - accuracy: 0.9993 - f1: 0.9993 - val_loss: 0.1594 - val_accuracy: 0.9759 - val_f1: 0.9762\n",
            "Epoch 36/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0039 - accuracy: 0.9994 - f1: 0.9994 - val_loss: 0.1437 - val_accuracy: 0.9802 - val_f1: 0.9804\n",
            "Epoch 37/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0038 - accuracy: 0.9994 - f1: 0.9994 - val_loss: 0.1559 - val_accuracy: 0.9775 - val_f1: 0.9777\n",
            "Epoch 38/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0039 - accuracy: 0.9993 - f1: 0.9993 - val_loss: 0.1698 - val_accuracy: 0.9767 - val_f1: 0.9767\n",
            "Epoch 39/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0044 - accuracy: 0.9991 - f1: 0.9991 - val_loss: 0.1510 - val_accuracy: 0.9793 - val_f1: 0.9793\n",
            "Epoch 40/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0035 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1484 - val_accuracy: 0.9795 - val_f1: 0.9794\n",
            "Epoch 41/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0043 - accuracy: 0.9992 - f1: 0.9992 - val_loss: 0.1686 - val_accuracy: 0.9771 - val_f1: 0.9774\n",
            "Epoch 42/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0046 - accuracy: 0.9993 - f1: 0.9993 - val_loss: 0.1673 - val_accuracy: 0.9770 - val_f1: 0.9771\n",
            "Epoch 43/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0042 - accuracy: 0.9994 - f1: 0.9994 - val_loss: 0.1567 - val_accuracy: 0.9796 - val_f1: 0.9796\n",
            "Epoch 44/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0041 - accuracy: 0.9993 - f1: 0.9993 - val_loss: 0.1461 - val_accuracy: 0.9792 - val_f1: 0.9793\n",
            "Epoch 45/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0037 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1676 - val_accuracy: 0.9764 - val_f1: 0.9764\n",
            "Epoch 46/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0037 - accuracy: 0.9992 - f1: 0.9993 - val_loss: 0.1562 - val_accuracy: 0.9785 - val_f1: 0.9786\n",
            "Epoch 47/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0041 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1659 - val_accuracy: 0.9772 - val_f1: 0.9772\n",
            "Epoch 48/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0036 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1733 - val_accuracy: 0.9757 - val_f1: 0.9757\n",
            "Epoch 49/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0046 - accuracy: 0.9990 - f1: 0.9990 - val_loss: 0.1540 - val_accuracy: 0.9794 - val_f1: 0.9796\n",
            "Epoch 50/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0035 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1581 - val_accuracy: 0.9805 - val_f1: 0.9805\n",
            "Epoch 51/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0042 - accuracy: 0.9991 - f1: 0.9991 - val_loss: 0.1772 - val_accuracy: 0.9768 - val_f1: 0.9769\n",
            "Epoch 52/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0035 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1492 - val_accuracy: 0.9799 - val_f1: 0.9800\n",
            "Epoch 53/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0039 - accuracy: 0.9994 - f1: 0.9994 - val_loss: 0.1645 - val_accuracy: 0.9771 - val_f1: 0.9772\n",
            "Epoch 54/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0037 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1584 - val_accuracy: 0.9783 - val_f1: 0.9784\n",
            "Epoch 55/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0035 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1609 - val_accuracy: 0.9786 - val_f1: 0.9786\n",
            "Epoch 56/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0041 - accuracy: 0.9992 - f1: 0.9992 - val_loss: 0.1668 - val_accuracy: 0.9783 - val_f1: 0.9784\n",
            "Epoch 57/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0030 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1736 - val_accuracy: 0.9779 - val_f1: 0.9781\n",
            "Epoch 58/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0042 - accuracy: 0.9993 - f1: 0.9993 - val_loss: 0.1708 - val_accuracy: 0.9781 - val_f1: 0.9781\n",
            "Epoch 59/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0032 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1551 - val_accuracy: 0.9792 - val_f1: 0.9792\n",
            "Epoch 60/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0036 - accuracy: 0.9994 - f1: 0.9994 - val_loss: 0.1735 - val_accuracy: 0.9792 - val_f1: 0.9793\n",
            "Epoch 61/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0038 - accuracy: 0.9994 - f1: 0.9994 - val_loss: 0.1556 - val_accuracy: 0.9801 - val_f1: 0.9801\n",
            "Epoch 62/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0037 - accuracy: 0.9994 - f1: 0.9994 - val_loss: 0.1664 - val_accuracy: 0.9784 - val_f1: 0.9786\n",
            "Epoch 63/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0034 - accuracy: 0.9994 - f1: 0.9994 - val_loss: 0.1758 - val_accuracy: 0.9772 - val_f1: 0.9774\n",
            "Epoch 64/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0036 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1536 - val_accuracy: 0.9796 - val_f1: 0.9794\n",
            "Epoch 65/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0032 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1673 - val_accuracy: 0.9785 - val_f1: 0.9784\n",
            "Epoch 66/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0037 - accuracy: 0.9994 - f1: 0.9994 - val_loss: 0.1649 - val_accuracy: 0.9795 - val_f1: 0.9795\n",
            "Epoch 67/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0032 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1695 - val_accuracy: 0.9773 - val_f1: 0.9775\n",
            "Epoch 68/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0031 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1628 - val_accuracy: 0.9787 - val_f1: 0.9790\n",
            "Epoch 69/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0029 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1724 - val_accuracy: 0.9776 - val_f1: 0.9777\n",
            "Epoch 70/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0031 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1786 - val_accuracy: 0.9773 - val_f1: 0.9774\n",
            "Epoch 71/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0035 - accuracy: 0.9994 - f1: 0.9994 - val_loss: 0.1553 - val_accuracy: 0.9780 - val_f1: 0.9781\n",
            "Epoch 72/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0035 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1616 - val_accuracy: 0.9803 - val_f1: 0.9804\n",
            "Epoch 73/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0032 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1511 - val_accuracy: 0.9793 - val_f1: 0.9793\n",
            "Epoch 74/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0032 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1507 - val_accuracy: 0.9797 - val_f1: 0.9798\n",
            "Epoch 75/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0035 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1753 - val_accuracy: 0.9762 - val_f1: 0.9763\n",
            "Epoch 76/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0029 - accuracy: 0.9994 - f1: 0.9994 - val_loss: 0.1490 - val_accuracy: 0.9791 - val_f1: 0.9791\n",
            "Epoch 77/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0028 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1594 - val_accuracy: 0.9782 - val_f1: 0.9782\n",
            "Epoch 78/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0033 - accuracy: 0.9994 - f1: 0.9994 - val_loss: 0.1594 - val_accuracy: 0.9790 - val_f1: 0.9790\n",
            "Epoch 79/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0032 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1511 - val_accuracy: 0.9805 - val_f1: 0.9806\n",
            "Epoch 80/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0031 - accuracy: 0.9995 - f1: 0.9996 - val_loss: 0.1926 - val_accuracy: 0.9770 - val_f1: 0.9770\n",
            "Epoch 81/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0026 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1560 - val_accuracy: 0.9803 - val_f1: 0.9804\n",
            "Epoch 82/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0034 - accuracy: 0.9994 - f1: 0.9994 - val_loss: 0.1466 - val_accuracy: 0.9793 - val_f1: 0.9794\n",
            "Epoch 83/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0028 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1527 - val_accuracy: 0.9796 - val_f1: 0.9798\n",
            "Epoch 84/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0031 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1547 - val_accuracy: 0.9797 - val_f1: 0.9798\n",
            "Epoch 85/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0031 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1594 - val_accuracy: 0.9787 - val_f1: 0.9788\n",
            "Epoch 86/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0032 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1586 - val_accuracy: 0.9791 - val_f1: 0.9793\n",
            "Epoch 87/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0031 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1506 - val_accuracy: 0.9822 - val_f1: 0.9823\n",
            "Epoch 88/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0033 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1629 - val_accuracy: 0.9783 - val_f1: 0.9783\n",
            "Epoch 89/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0030 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1560 - val_accuracy: 0.9787 - val_f1: 0.9787\n",
            "Epoch 90/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0028 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1506 - val_accuracy: 0.9803 - val_f1: 0.9803\n",
            "Epoch 91/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0025 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1743 - val_accuracy: 0.9783 - val_f1: 0.9783\n",
            "Epoch 92/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0028 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1696 - val_accuracy: 0.9783 - val_f1: 0.9783\n",
            "Epoch 93/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0028 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1615 - val_accuracy: 0.9773 - val_f1: 0.9774\n",
            "Epoch 94/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0032 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1894 - val_accuracy: 0.9753 - val_f1: 0.9753\n",
            "Epoch 95/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0032 - accuracy: 0.9994 - f1: 0.9994 - val_loss: 0.1652 - val_accuracy: 0.9775 - val_f1: 0.9777\n",
            "Epoch 96/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0027 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1596 - val_accuracy: 0.9797 - val_f1: 0.9797\n",
            "Epoch 97/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0033 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1731 - val_accuracy: 0.9778 - val_f1: 0.9778\n",
            "Epoch 98/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0026 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1671 - val_accuracy: 0.9787 - val_f1: 0.9787\n",
            "Epoch 99/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0030 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1551 - val_accuracy: 0.9801 - val_f1: 0.9802\n",
            "Epoch 100/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0030 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1756 - val_accuracy: 0.9774 - val_f1: 0.9777\n",
            "Epoch 101/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0029 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1639 - val_accuracy: 0.9791 - val_f1: 0.9791\n",
            "Epoch 102/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0023 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1620 - val_accuracy: 0.9795 - val_f1: 0.9796\n",
            "Epoch 103/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0032 - accuracy: 0.9994 - f1: 0.9994 - val_loss: 0.1665 - val_accuracy: 0.9775 - val_f1: 0.9774\n",
            "Epoch 104/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0029 - accuracy: 0.9995 - f1: 0.9994 - val_loss: 0.1552 - val_accuracy: 0.9797 - val_f1: 0.9798\n",
            "Epoch 105/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0027 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1575 - val_accuracy: 0.9794 - val_f1: 0.9794\n",
            "Epoch 106/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0026 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1712 - val_accuracy: 0.9774 - val_f1: 0.9774\n",
            "Epoch 107/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0027 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1962 - val_accuracy: 0.9745 - val_f1: 0.9746\n",
            "Epoch 108/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0029 - accuracy: 0.9994 - f1: 0.9994 - val_loss: 0.1618 - val_accuracy: 0.9781 - val_f1: 0.9780\n",
            "Epoch 109/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0030 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1805 - val_accuracy: 0.9772 - val_f1: 0.9774\n",
            "Epoch 110/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0029 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1675 - val_accuracy: 0.9793 - val_f1: 0.9795\n",
            "Epoch 111/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0025 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1718 - val_accuracy: 0.9780 - val_f1: 0.9782\n",
            "Epoch 112/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0030 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1653 - val_accuracy: 0.9793 - val_f1: 0.9793\n",
            "Epoch 113/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0029 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1563 - val_accuracy: 0.9803 - val_f1: 0.9803\n",
            "Epoch 114/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0026 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1617 - val_accuracy: 0.9781 - val_f1: 0.9781\n",
            "Epoch 115/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0027 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1736 - val_accuracy: 0.9783 - val_f1: 0.9782\n",
            "Epoch 116/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0028 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1637 - val_accuracy: 0.9783 - val_f1: 0.9783\n",
            "Epoch 117/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0020 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1565 - val_accuracy: 0.9783 - val_f1: 0.9783\n",
            "Epoch 118/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0032 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1513 - val_accuracy: 0.9799 - val_f1: 0.9800\n",
            "Epoch 119/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0027 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1607 - val_accuracy: 0.9778 - val_f1: 0.9779\n",
            "Epoch 120/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0028 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1519 - val_accuracy: 0.9802 - val_f1: 0.9802\n",
            "Epoch 121/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0026 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1578 - val_accuracy: 0.9789 - val_f1: 0.9788\n",
            "Epoch 122/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0022 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1573 - val_accuracy: 0.9793 - val_f1: 0.9793\n",
            "Epoch 123/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0024 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1508 - val_accuracy: 0.9798 - val_f1: 0.9798\n",
            "Epoch 124/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0029 - accuracy: 0.9995 - f1: 0.9996 - val_loss: 0.1565 - val_accuracy: 0.9777 - val_f1: 0.9777\n",
            "Epoch 125/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0028 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1457 - val_accuracy: 0.9803 - val_f1: 0.9803\n",
            "Epoch 126/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0025 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1583 - val_accuracy: 0.9795 - val_f1: 0.9794\n",
            "Epoch 127/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0025 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1461 - val_accuracy: 0.9809 - val_f1: 0.9809\n",
            "Epoch 128/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0026 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1511 - val_accuracy: 0.9797 - val_f1: 0.9797\n",
            "Epoch 129/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0025 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1456 - val_accuracy: 0.9803 - val_f1: 0.9804\n",
            "Epoch 130/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0023 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1564 - val_accuracy: 0.9791 - val_f1: 0.9791\n",
            "Epoch 131/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0020 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1480 - val_accuracy: 0.9802 - val_f1: 0.9802\n",
            "Epoch 132/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0029 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1507 - val_accuracy: 0.9787 - val_f1: 0.9788\n",
            "Epoch 133/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0019 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1497 - val_accuracy: 0.9802 - val_f1: 0.9802\n",
            "Epoch 134/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0029 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1503 - val_accuracy: 0.9797 - val_f1: 0.9798\n",
            "Epoch 135/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0027 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1622 - val_accuracy: 0.9796 - val_f1: 0.9799\n",
            "Epoch 136/1000\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0026 - accuracy: 0.9995 - f1: 0.9996 - val_loss: 0.1749 - val_accuracy: 0.9758 - val_f1: 0.9759\n",
            "Epoch 137/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0030 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1511 - val_accuracy: 0.9799 - val_f1: 0.9799\n",
            "Epoch 138/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0027 - accuracy: 0.9994 - f1: 0.9994 - val_loss: 0.1711 - val_accuracy: 0.9777 - val_f1: 0.9777\n",
            "Epoch 139/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0030 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1364 - val_accuracy: 0.9817 - val_f1: 0.9816\n",
            "Epoch 140/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0028 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1426 - val_accuracy: 0.9804 - val_f1: 0.9805\n",
            "Epoch 141/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0023 - accuracy: 0.9998 - f1: 0.9997 - val_loss: 0.1455 - val_accuracy: 0.9797 - val_f1: 0.9797\n",
            "Epoch 142/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0023 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1460 - val_accuracy: 0.9800 - val_f1: 0.9800\n",
            "Epoch 143/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0024 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1494 - val_accuracy: 0.9804 - val_f1: 0.9804\n",
            "Epoch 144/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0026 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1528 - val_accuracy: 0.9793 - val_f1: 0.9795\n",
            "Epoch 145/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0024 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1465 - val_accuracy: 0.9793 - val_f1: 0.9795\n",
            "Epoch 146/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0027 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1550 - val_accuracy: 0.9799 - val_f1: 0.9799\n",
            "Epoch 147/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0028 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1884 - val_accuracy: 0.9773 - val_f1: 0.9775\n",
            "Epoch 148/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0019 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1661 - val_accuracy: 0.9783 - val_f1: 0.9785\n",
            "Epoch 149/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0023 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1633 - val_accuracy: 0.9784 - val_f1: 0.9785\n",
            "Epoch 150/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0026 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1588 - val_accuracy: 0.9793 - val_f1: 0.9793\n",
            "Epoch 151/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0029 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1907 - val_accuracy: 0.9752 - val_f1: 0.9753\n",
            "Epoch 152/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0022 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1545 - val_accuracy: 0.9795 - val_f1: 0.9798\n",
            "Epoch 153/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0022 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1721 - val_accuracy: 0.9772 - val_f1: 0.9773\n",
            "Epoch 154/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0020 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1623 - val_accuracy: 0.9793 - val_f1: 0.9795\n",
            "Epoch 155/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0024 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1533 - val_accuracy: 0.9801 - val_f1: 0.9802\n",
            "Epoch 156/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0021 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1682 - val_accuracy: 0.9786 - val_f1: 0.9785\n",
            "Epoch 157/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0024 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1514 - val_accuracy: 0.9805 - val_f1: 0.9805\n",
            "Epoch 158/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0024 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1525 - val_accuracy: 0.9803 - val_f1: 0.9803\n",
            "Epoch 159/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0024 - accuracy: 0.9996 - f1: 0.9997 - val_loss: 0.1529 - val_accuracy: 0.9790 - val_f1: 0.9791\n",
            "Epoch 160/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0019 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1526 - val_accuracy: 0.9798 - val_f1: 0.9800\n",
            "Epoch 161/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0026 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1467 - val_accuracy: 0.9808 - val_f1: 0.9809\n",
            "Epoch 162/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0026 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1515 - val_accuracy: 0.9798 - val_f1: 0.9800\n",
            "Epoch 163/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0020 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1527 - val_accuracy: 0.9787 - val_f1: 0.9789\n",
            "Epoch 164/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0021 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1478 - val_accuracy: 0.9801 - val_f1: 0.9800\n",
            "Epoch 165/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0022 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1487 - val_accuracy: 0.9803 - val_f1: 0.9803\n",
            "Epoch 166/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0026 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1529 - val_accuracy: 0.9800 - val_f1: 0.9802\n",
            "Epoch 167/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0021 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1628 - val_accuracy: 0.9793 - val_f1: 0.9792\n",
            "Epoch 168/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0022 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1648 - val_accuracy: 0.9777 - val_f1: 0.9777\n",
            "Epoch 169/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0024 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1538 - val_accuracy: 0.9793 - val_f1: 0.9793\n",
            "Epoch 170/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0022 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1795 - val_accuracy: 0.9752 - val_f1: 0.9753\n",
            "Epoch 171/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0023 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1416 - val_accuracy: 0.9797 - val_f1: 0.9798\n",
            "Epoch 172/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0020 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1387 - val_accuracy: 0.9803 - val_f1: 0.9802\n",
            "Epoch 173/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0023 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1680 - val_accuracy: 0.9781 - val_f1: 0.9782\n",
            "Epoch 174/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0023 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1508 - val_accuracy: 0.9787 - val_f1: 0.9787\n",
            "Epoch 175/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0024 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1549 - val_accuracy: 0.9791 - val_f1: 0.9792\n",
            "Epoch 176/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0026 - accuracy: 0.9996 - f1: 0.9995 - val_loss: 0.1609 - val_accuracy: 0.9762 - val_f1: 0.9764\n",
            "Epoch 177/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0022 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1666 - val_accuracy: 0.9774 - val_f1: 0.9776\n",
            "Epoch 178/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0024 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1431 - val_accuracy: 0.9803 - val_f1: 0.9804\n",
            "Epoch 179/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0024 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1605 - val_accuracy: 0.9783 - val_f1: 0.9784\n",
            "Epoch 180/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0017 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1546 - val_accuracy: 0.9791 - val_f1: 0.9792\n",
            "Epoch 181/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0022 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1832 - val_accuracy: 0.9755 - val_f1: 0.9758\n",
            "Epoch 182/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0025 - accuracy: 0.9996 - f1: 0.9997 - val_loss: 0.1795 - val_accuracy: 0.9763 - val_f1: 0.9764\n",
            "Epoch 183/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0029 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1551 - val_accuracy: 0.9790 - val_f1: 0.9793\n",
            "Epoch 184/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0025 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1548 - val_accuracy: 0.9789 - val_f1: 0.9792\n",
            "Epoch 185/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0030 - accuracy: 0.9993 - f1: 0.9993 - val_loss: 0.1500 - val_accuracy: 0.9791 - val_f1: 0.9790\n",
            "Epoch 186/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0020 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1624 - val_accuracy: 0.9794 - val_f1: 0.9795\n",
            "Epoch 187/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0024 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1423 - val_accuracy: 0.9801 - val_f1: 0.9801\n",
            "Epoch 188/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0019 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1709 - val_accuracy: 0.9773 - val_f1: 0.9775\n",
            "Epoch 189/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0025 - accuracy: 0.9996 - f1: 0.9997 - val_loss: 0.1588 - val_accuracy: 0.9785 - val_f1: 0.9786\n",
            "Epoch 190/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1479 - val_accuracy: 0.9787 - val_f1: 0.9788\n",
            "Epoch 191/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0022 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1418 - val_accuracy: 0.9801 - val_f1: 0.9802\n",
            "Epoch 192/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0020 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1462 - val_accuracy: 0.9801 - val_f1: 0.9801\n",
            "Epoch 193/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0024 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1521 - val_accuracy: 0.9793 - val_f1: 0.9795\n",
            "Epoch 194/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0020 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1452 - val_accuracy: 0.9797 - val_f1: 0.9799\n",
            "Epoch 195/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0022 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1505 - val_accuracy: 0.9774 - val_f1: 0.9777\n",
            "Epoch 196/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0023 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1555 - val_accuracy: 0.9796 - val_f1: 0.9799\n",
            "Epoch 197/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0024 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1484 - val_accuracy: 0.9797 - val_f1: 0.9799\n",
            "Epoch 198/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0024 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1428 - val_accuracy: 0.9796 - val_f1: 0.9797\n",
            "Epoch 199/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0020 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1502 - val_accuracy: 0.9797 - val_f1: 0.9798\n",
            "Epoch 200/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0021 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1609 - val_accuracy: 0.9797 - val_f1: 0.9796\n",
            "Epoch 201/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0029 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1695 - val_accuracy: 0.9785 - val_f1: 0.9787\n",
            "Epoch 202/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0027 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1755 - val_accuracy: 0.9771 - val_f1: 0.9772\n",
            "Epoch 203/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0022 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1576 - val_accuracy: 0.9794 - val_f1: 0.9795\n",
            "Epoch 204/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0021 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1677 - val_accuracy: 0.9782 - val_f1: 0.9783\n",
            "Epoch 205/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0027 - accuracy: 0.9994 - f1: 0.9994 - val_loss: 0.1562 - val_accuracy: 0.9782 - val_f1: 0.9783\n",
            "Epoch 206/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0025 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1410 - val_accuracy: 0.9797 - val_f1: 0.9797\n",
            "Epoch 207/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0025 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1541 - val_accuracy: 0.9780 - val_f1: 0.9782\n",
            "Epoch 208/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0024 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1709 - val_accuracy: 0.9758 - val_f1: 0.9759\n",
            "Epoch 209/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0020 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1603 - val_accuracy: 0.9772 - val_f1: 0.9774\n",
            "Epoch 210/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1521 - val_accuracy: 0.9784 - val_f1: 0.9787\n",
            "Epoch 211/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1535 - val_accuracy: 0.9786 - val_f1: 0.9786\n",
            "Epoch 212/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0021 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1542 - val_accuracy: 0.9791 - val_f1: 0.9792\n",
            "Epoch 213/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0016 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1585 - val_accuracy: 0.9784 - val_f1: 0.9783\n",
            "Epoch 214/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0022 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1497 - val_accuracy: 0.9796 - val_f1: 0.9798\n",
            "Epoch 215/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1621 - val_accuracy: 0.9776 - val_f1: 0.9777\n",
            "Epoch 216/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0020 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1598 - val_accuracy: 0.9789 - val_f1: 0.9789\n",
            "Epoch 217/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0022 - accuracy: 0.9997 - f1: 0.9996 - val_loss: 0.1857 - val_accuracy: 0.9755 - val_f1: 0.9756\n",
            "Epoch 218/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0019 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1533 - val_accuracy: 0.9788 - val_f1: 0.9790\n",
            "Epoch 219/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0020 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1595 - val_accuracy: 0.9793 - val_f1: 0.9793\n",
            "Epoch 220/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0031 - accuracy: 0.9994 - f1: 0.9994 - val_loss: 0.1941 - val_accuracy: 0.9756 - val_f1: 0.9757\n",
            "Epoch 221/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0021 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1667 - val_accuracy: 0.9793 - val_f1: 0.9794\n",
            "Epoch 222/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0023 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1487 - val_accuracy: 0.9792 - val_f1: 0.9792\n",
            "Epoch 223/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0019 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1611 - val_accuracy: 0.9769 - val_f1: 0.9771\n",
            "Epoch 224/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1655 - val_accuracy: 0.9764 - val_f1: 0.9765\n",
            "Epoch 225/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0023 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1550 - val_accuracy: 0.9791 - val_f1: 0.9793\n",
            "Epoch 226/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0025 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1603 - val_accuracy: 0.9779 - val_f1: 0.9779\n",
            "Epoch 227/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0026 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1561 - val_accuracy: 0.9803 - val_f1: 0.9804\n",
            "Epoch 228/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0022 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1759 - val_accuracy: 0.9745 - val_f1: 0.9747\n",
            "Epoch 229/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0019 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1571 - val_accuracy: 0.9800 - val_f1: 0.9799\n",
            "Epoch 230/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0019 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1647 - val_accuracy: 0.9788 - val_f1: 0.9788\n",
            "Epoch 231/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0021 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1510 - val_accuracy: 0.9793 - val_f1: 0.9793\n",
            "Epoch 232/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0020 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1615 - val_accuracy: 0.9768 - val_f1: 0.9769\n",
            "Epoch 233/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0018 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1732 - val_accuracy: 0.9763 - val_f1: 0.9762\n",
            "Epoch 234/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0025 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1637 - val_accuracy: 0.9783 - val_f1: 0.9784\n",
            "Epoch 235/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0019 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1751 - val_accuracy: 0.9787 - val_f1: 0.9789\n",
            "Epoch 236/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0027 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1719 - val_accuracy: 0.9786 - val_f1: 0.9787\n",
            "Epoch 237/1000\n",
            "188/188 [==============================] - 3s 13ms/step - loss: 0.0024 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1491 - val_accuracy: 0.9797 - val_f1: 0.9796\n",
            "Epoch 238/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0019 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1577 - val_accuracy: 0.9785 - val_f1: 0.9788\n",
            "Epoch 239/1000\n",
            "188/188 [==============================] - 3s 13ms/step - loss: 0.0019 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1588 - val_accuracy: 0.9791 - val_f1: 0.9791\n",
            "Epoch 240/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0022 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1523 - val_accuracy: 0.9792 - val_f1: 0.9793\n",
            "Epoch 241/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0021 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1660 - val_accuracy: 0.9788 - val_f1: 0.9790\n",
            "Epoch 242/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0021 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1535 - val_accuracy: 0.9794 - val_f1: 0.9796\n",
            "Epoch 243/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0020 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1867 - val_accuracy: 0.9762 - val_f1: 0.9763\n",
            "Epoch 244/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0021 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1514 - val_accuracy: 0.9795 - val_f1: 0.9795\n",
            "Epoch 245/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0017 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1458 - val_accuracy: 0.9802 - val_f1: 0.9803\n",
            "Epoch 246/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1596 - val_accuracy: 0.9795 - val_f1: 0.9794\n",
            "Epoch 247/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0026 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1600 - val_accuracy: 0.9790 - val_f1: 0.9792\n",
            "Epoch 248/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0019 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1882 - val_accuracy: 0.9721 - val_f1: 0.9721\n",
            "Epoch 249/1000\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0023 - accuracy: 0.9996 - f1: 0.9997 - val_loss: 0.1578 - val_accuracy: 0.9787 - val_f1: 0.9789\n",
            "Epoch 250/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0021 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1525 - val_accuracy: 0.9788 - val_f1: 0.9789\n",
            "Epoch 251/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0019 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1622 - val_accuracy: 0.9783 - val_f1: 0.9784\n",
            "Epoch 252/1000\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0023 - accuracy: 0.9996 - f1: 0.9997 - val_loss: 0.1650 - val_accuracy: 0.9772 - val_f1: 0.9774\n",
            "Epoch 253/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1505 - val_accuracy: 0.9794 - val_f1: 0.9794\n",
            "Epoch 254/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1535 - val_accuracy: 0.9779 - val_f1: 0.9779\n",
            "Epoch 255/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0024 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1612 - val_accuracy: 0.9761 - val_f1: 0.9764\n",
            "Epoch 256/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1494 - val_accuracy: 0.9791 - val_f1: 0.9792\n",
            "Epoch 257/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1544 - val_accuracy: 0.9793 - val_f1: 0.9792\n",
            "Epoch 258/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0021 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1515 - val_accuracy: 0.9789 - val_f1: 0.9789\n",
            "Epoch 259/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0020 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1669 - val_accuracy: 0.9781 - val_f1: 0.9782\n",
            "Epoch 260/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0019 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1532 - val_accuracy: 0.9797 - val_f1: 0.9797\n",
            "Epoch 261/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0022 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1523 - val_accuracy: 0.9790 - val_f1: 0.9791\n",
            "Epoch 262/1000\n",
            "188/188 [==============================] - 3s 13ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1546 - val_accuracy: 0.9778 - val_f1: 0.9778\n",
            "Epoch 263/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0022 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.2040 - val_accuracy: 0.9724 - val_f1: 0.9725\n",
            "Epoch 264/1000\n",
            "188/188 [==============================] - 3s 13ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1521 - val_accuracy: 0.9797 - val_f1: 0.9798\n",
            "Epoch 265/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0019 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1509 - val_accuracy: 0.9773 - val_f1: 0.9776\n",
            "Epoch 266/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0025 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1428 - val_accuracy: 0.9793 - val_f1: 0.9794\n",
            "Epoch 267/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0019 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1659 - val_accuracy: 0.9778 - val_f1: 0.9780\n",
            "Epoch 268/1000\n",
            "188/188 [==============================] - 2s 13ms/step - loss: 0.0023 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1627 - val_accuracy: 0.9769 - val_f1: 0.9770\n",
            "Epoch 269/1000\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0021 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1526 - val_accuracy: 0.9783 - val_f1: 0.9783\n",
            "Epoch 270/1000\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1915 - val_accuracy: 0.9743 - val_f1: 0.9744\n",
            "Epoch 271/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0021 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1570 - val_accuracy: 0.9787 - val_f1: 0.9788\n",
            "Epoch 272/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0029 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1594 - val_accuracy: 0.9771 - val_f1: 0.9772\n",
            "Epoch 273/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0023 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1775 - val_accuracy: 0.9763 - val_f1: 0.9766\n",
            "Epoch 274/1000\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0021 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1528 - val_accuracy: 0.9785 - val_f1: 0.9786\n",
            "Epoch 275/1000\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1622 - val_accuracy: 0.9779 - val_f1: 0.9779\n",
            "Epoch 276/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0019 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1544 - val_accuracy: 0.9791 - val_f1: 0.9792\n",
            "Epoch 277/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1573 - val_accuracy: 0.9801 - val_f1: 0.9801\n",
            "Epoch 278/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1484 - val_accuracy: 0.9801 - val_f1: 0.9800\n",
            "Epoch 279/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0021 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1494 - val_accuracy: 0.9806 - val_f1: 0.9806\n",
            "Epoch 280/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1577 - val_accuracy: 0.9788 - val_f1: 0.9788\n",
            "Epoch 281/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1470 - val_accuracy: 0.9784 - val_f1: 0.9784\n",
            "Epoch 282/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1436 - val_accuracy: 0.9790 - val_f1: 0.9790\n",
            "Epoch 283/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1534 - val_accuracy: 0.9785 - val_f1: 0.9785\n",
            "Epoch 284/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0019 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1677 - val_accuracy: 0.9780 - val_f1: 0.9779\n",
            "Epoch 285/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1592 - val_accuracy: 0.9779 - val_f1: 0.9781\n",
            "Epoch 286/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0020 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1532 - val_accuracy: 0.9771 - val_f1: 0.9772\n",
            "Epoch 287/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1504 - val_accuracy: 0.9792 - val_f1: 0.9794\n",
            "Epoch 288/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0026 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1492 - val_accuracy: 0.9782 - val_f1: 0.9781\n",
            "Epoch 289/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1367 - val_accuracy: 0.9794 - val_f1: 0.9794\n",
            "Epoch 290/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1423 - val_accuracy: 0.9795 - val_f1: 0.9796\n",
            "Epoch 291/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0020 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1447 - val_accuracy: 0.9793 - val_f1: 0.9792\n",
            "Epoch 292/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1684 - val_accuracy: 0.9788 - val_f1: 0.9790\n",
            "Epoch 293/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1539 - val_accuracy: 0.9784 - val_f1: 0.9786\n",
            "Epoch 294/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0023 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1437 - val_accuracy: 0.9799 - val_f1: 0.9800\n",
            "Epoch 295/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1591 - val_accuracy: 0.9770 - val_f1: 0.9772\n",
            "Epoch 296/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1446 - val_accuracy: 0.9783 - val_f1: 0.9785\n",
            "Epoch 297/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1684 - val_accuracy: 0.9779 - val_f1: 0.9780\n",
            "Epoch 298/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1816 - val_accuracy: 0.9738 - val_f1: 0.9738\n",
            "Epoch 299/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0021 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1557 - val_accuracy: 0.9783 - val_f1: 0.9784\n",
            "Epoch 300/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1634 - val_accuracy: 0.9778 - val_f1: 0.9779\n",
            "Epoch 301/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0021 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1475 - val_accuracy: 0.9795 - val_f1: 0.9796\n",
            "Epoch 302/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1603 - val_accuracy: 0.9753 - val_f1: 0.9755\n",
            "Epoch 303/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0021 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1484 - val_accuracy: 0.9788 - val_f1: 0.9790\n",
            "Epoch 304/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0023 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1633 - val_accuracy: 0.9776 - val_f1: 0.9778\n",
            "Epoch 305/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1775 - val_accuracy: 0.9762 - val_f1: 0.9762\n",
            "Epoch 306/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0022 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1413 - val_accuracy: 0.9804 - val_f1: 0.9803\n",
            "Epoch 307/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1450 - val_accuracy: 0.9799 - val_f1: 0.9800\n",
            "Epoch 308/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1595 - val_accuracy: 0.9771 - val_f1: 0.9772\n",
            "Epoch 309/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0021 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1541 - val_accuracy: 0.9781 - val_f1: 0.9781\n",
            "Epoch 310/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1563 - val_accuracy: 0.9779 - val_f1: 0.9780\n",
            "Epoch 311/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0020 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1437 - val_accuracy: 0.9790 - val_f1: 0.9792\n",
            "Epoch 312/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0019 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1447 - val_accuracy: 0.9790 - val_f1: 0.9791\n",
            "Epoch 313/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1521 - val_accuracy: 0.9787 - val_f1: 0.9788\n",
            "Epoch 314/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0022 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1549 - val_accuracy: 0.9790 - val_f1: 0.9789\n",
            "Epoch 315/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1552 - val_accuracy: 0.9789 - val_f1: 0.9790\n",
            "Epoch 316/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0025 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1454 - val_accuracy: 0.9797 - val_f1: 0.9799\n",
            "Epoch 317/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0015 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1450 - val_accuracy: 0.9800 - val_f1: 0.9801\n",
            "Epoch 318/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1739 - val_accuracy: 0.9761 - val_f1: 0.9761\n",
            "Epoch 319/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0026 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1665 - val_accuracy: 0.9765 - val_f1: 0.9767\n",
            "Epoch 320/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1514 - val_accuracy: 0.9781 - val_f1: 0.9781\n",
            "Epoch 321/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0020 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1432 - val_accuracy: 0.9793 - val_f1: 0.9795\n",
            "Epoch 322/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0027 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1446 - val_accuracy: 0.9797 - val_f1: 0.9798\n",
            "Epoch 323/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0023 - accuracy: 0.9996 - f1: 0.9997 - val_loss: 0.1566 - val_accuracy: 0.9789 - val_f1: 0.9790\n",
            "Epoch 324/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1496 - val_accuracy: 0.9794 - val_f1: 0.9795\n",
            "Epoch 325/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0019 - accuracy: 0.9998 - f1: 0.9997 - val_loss: 0.1642 - val_accuracy: 0.9770 - val_f1: 0.9771\n",
            "Epoch 326/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1677 - val_accuracy: 0.9763 - val_f1: 0.9763\n",
            "Epoch 327/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0014 - accuracy: 0.9999 - f1: 0.9998 - val_loss: 0.1424 - val_accuracy: 0.9787 - val_f1: 0.9786\n",
            "Epoch 328/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0015 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1502 - val_accuracy: 0.9791 - val_f1: 0.9792\n",
            "Epoch 329/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0021 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1538 - val_accuracy: 0.9787 - val_f1: 0.9788\n",
            "Epoch 330/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0018 - accuracy: 0.9996 - f1: 0.9997 - val_loss: 0.1457 - val_accuracy: 0.9795 - val_f1: 0.9796\n",
            "Epoch 331/1000\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1632 - val_accuracy: 0.9783 - val_f1: 0.9784\n",
            "Epoch 332/1000\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0020 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1481 - val_accuracy: 0.9794 - val_f1: 0.9796\n",
            "Epoch 333/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0020 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1435 - val_accuracy: 0.9787 - val_f1: 0.9789\n",
            "Epoch 334/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1773 - val_accuracy: 0.9739 - val_f1: 0.9741\n",
            "Epoch 335/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1554 - val_accuracy: 0.9779 - val_f1: 0.9780\n",
            "Epoch 336/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1442 - val_accuracy: 0.9793 - val_f1: 0.9796\n",
            "Epoch 337/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1426 - val_accuracy: 0.9787 - val_f1: 0.9787\n",
            "Epoch 338/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1645 - val_accuracy: 0.9767 - val_f1: 0.9768\n",
            "Epoch 339/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0026 - accuracy: 0.9994 - f1: 0.9994 - val_loss: 0.1593 - val_accuracy: 0.9761 - val_f1: 0.9762\n",
            "Epoch 340/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1513 - val_accuracy: 0.9789 - val_f1: 0.9790\n",
            "Epoch 341/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1463 - val_accuracy: 0.9792 - val_f1: 0.9792\n",
            "Epoch 342/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1594 - val_accuracy: 0.9758 - val_f1: 0.9761\n",
            "Epoch 343/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0020 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1387 - val_accuracy: 0.9796 - val_f1: 0.9796\n",
            "Epoch 344/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1529 - val_accuracy: 0.9791 - val_f1: 0.9792\n",
            "Epoch 345/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0021 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1482 - val_accuracy: 0.9772 - val_f1: 0.9772\n",
            "Epoch 346/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1495 - val_accuracy: 0.9788 - val_f1: 0.9791\n",
            "Epoch 347/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1518 - val_accuracy: 0.9793 - val_f1: 0.9794\n",
            "Epoch 348/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1530 - val_accuracy: 0.9793 - val_f1: 0.9796\n",
            "Epoch 349/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1465 - val_accuracy: 0.9797 - val_f1: 0.9798\n",
            "Epoch 350/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1556 - val_accuracy: 0.9795 - val_f1: 0.9796\n",
            "Epoch 351/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1475 - val_accuracy: 0.9784 - val_f1: 0.9785\n",
            "Epoch 352/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0020 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1584 - val_accuracy: 0.9778 - val_f1: 0.9779\n",
            "Epoch 353/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0022 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1493 - val_accuracy: 0.9801 - val_f1: 0.9802\n",
            "Epoch 354/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1494 - val_accuracy: 0.9792 - val_f1: 0.9792\n",
            "Epoch 355/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9996 - f1: 0.9997 - val_loss: 0.1522 - val_accuracy: 0.9787 - val_f1: 0.9788\n",
            "Epoch 356/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1553 - val_accuracy: 0.9784 - val_f1: 0.9784\n",
            "Epoch 357/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1579 - val_accuracy: 0.9780 - val_f1: 0.9780\n",
            "Epoch 358/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0023 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1467 - val_accuracy: 0.9796 - val_f1: 0.9796\n",
            "Epoch 359/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1579 - val_accuracy: 0.9781 - val_f1: 0.9783\n",
            "Epoch 360/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1480 - val_accuracy: 0.9797 - val_f1: 0.9798\n",
            "Epoch 361/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1482 - val_accuracy: 0.9786 - val_f1: 0.9786\n",
            "Epoch 362/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0023 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1423 - val_accuracy: 0.9787 - val_f1: 0.9788\n",
            "Epoch 363/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1494 - val_accuracy: 0.9787 - val_f1: 0.9788\n",
            "Epoch 364/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.2046 - val_accuracy: 0.9717 - val_f1: 0.9717\n",
            "Epoch 365/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1611 - val_accuracy: 0.9773 - val_f1: 0.9774\n",
            "Epoch 366/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0022 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1469 - val_accuracy: 0.9785 - val_f1: 0.9785\n",
            "Epoch 367/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1526 - val_accuracy: 0.9793 - val_f1: 0.9792\n",
            "Epoch 368/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1605 - val_accuracy: 0.9796 - val_f1: 0.9796\n",
            "Epoch 369/1000\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1581 - val_accuracy: 0.9772 - val_f1: 0.9774\n",
            "Epoch 370/1000\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1475 - val_accuracy: 0.9793 - val_f1: 0.9795\n",
            "Epoch 371/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1484 - val_accuracy: 0.9793 - val_f1: 0.9795\n",
            "Epoch 372/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0022 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1640 - val_accuracy: 0.9766 - val_f1: 0.9767\n",
            "Epoch 373/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1486 - val_accuracy: 0.9794 - val_f1: 0.9794\n",
            "Epoch 374/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0026 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1591 - val_accuracy: 0.9778 - val_f1: 0.9779\n",
            "Epoch 375/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0020 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1439 - val_accuracy: 0.9798 - val_f1: 0.9799\n",
            "Epoch 376/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0019 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1456 - val_accuracy: 0.9783 - val_f1: 0.9786\n",
            "Epoch 377/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1583 - val_accuracy: 0.9784 - val_f1: 0.9785\n",
            "Epoch 378/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0020 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1528 - val_accuracy: 0.9780 - val_f1: 0.9781\n",
            "Epoch 379/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1533 - val_accuracy: 0.9782 - val_f1: 0.9785\n",
            "Epoch 380/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0021 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1410 - val_accuracy: 0.9790 - val_f1: 0.9792\n",
            "Epoch 381/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1641 - val_accuracy: 0.9776 - val_f1: 0.9778\n",
            "Epoch 382/1000\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0019 - accuracy: 0.9996 - f1: 0.9997 - val_loss: 0.1414 - val_accuracy: 0.9797 - val_f1: 0.9799\n",
            "Epoch 383/1000\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1650 - val_accuracy: 0.9787 - val_f1: 0.9787\n",
            "Epoch 384/1000\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1651 - val_accuracy: 0.9777 - val_f1: 0.9779\n",
            "Epoch 385/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1578 - val_accuracy: 0.9787 - val_f1: 0.9788\n",
            "Epoch 386/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0024 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1442 - val_accuracy: 0.9803 - val_f1: 0.9804\n",
            "Epoch 387/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0020 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1480 - val_accuracy: 0.9795 - val_f1: 0.9796\n",
            "Epoch 388/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1463 - val_accuracy: 0.9780 - val_f1: 0.9781\n",
            "Epoch 389/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0027 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1514 - val_accuracy: 0.9778 - val_f1: 0.9779\n",
            "Epoch 390/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1621 - val_accuracy: 0.9768 - val_f1: 0.9770\n",
            "Epoch 391/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0022 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1561 - val_accuracy: 0.9778 - val_f1: 0.9780\n",
            "Epoch 392/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1493 - val_accuracy: 0.9792 - val_f1: 0.9791\n",
            "Epoch 393/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1528 - val_accuracy: 0.9777 - val_f1: 0.9781\n",
            "Epoch 394/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1493 - val_accuracy: 0.9785 - val_f1: 0.9786\n",
            "Epoch 395/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1498 - val_accuracy: 0.9793 - val_f1: 0.9795\n",
            "Epoch 396/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0026 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1564 - val_accuracy: 0.9766 - val_f1: 0.9767\n",
            "Epoch 397/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1459 - val_accuracy: 0.9807 - val_f1: 0.9806\n",
            "Epoch 398/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0019 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1474 - val_accuracy: 0.9792 - val_f1: 0.9792\n",
            "Epoch 399/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0021 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1638 - val_accuracy: 0.9768 - val_f1: 0.9768\n",
            "Epoch 400/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1552 - val_accuracy: 0.9768 - val_f1: 0.9769\n",
            "Epoch 401/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1506 - val_accuracy: 0.9793 - val_f1: 0.9793\n",
            "Epoch 402/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0020 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1481 - val_accuracy: 0.9780 - val_f1: 0.9782\n",
            "Epoch 403/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1471 - val_accuracy: 0.9798 - val_f1: 0.9798\n",
            "Epoch 404/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1575 - val_accuracy: 0.9767 - val_f1: 0.9767\n",
            "Epoch 405/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1487 - val_accuracy: 0.9784 - val_f1: 0.9786\n",
            "Epoch 406/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0023 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1467 - val_accuracy: 0.9789 - val_f1: 0.9791\n",
            "Epoch 407/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9997 - f1: 0.9996 - val_loss: 0.1741 - val_accuracy: 0.9758 - val_f1: 0.9759\n",
            "Epoch 408/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1565 - val_accuracy: 0.9776 - val_f1: 0.9777\n",
            "Epoch 409/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1491 - val_accuracy: 0.9789 - val_f1: 0.9790\n",
            "Epoch 410/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1489 - val_accuracy: 0.9785 - val_f1: 0.9786\n",
            "Epoch 411/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1476 - val_accuracy: 0.9792 - val_f1: 0.9794\n",
            "Epoch 412/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1563 - val_accuracy: 0.9782 - val_f1: 0.9783\n",
            "Epoch 413/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1493 - val_accuracy: 0.9792 - val_f1: 0.9791\n",
            "Epoch 414/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1627 - val_accuracy: 0.9782 - val_f1: 0.9783\n",
            "Epoch 415/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0021 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1450 - val_accuracy: 0.9791 - val_f1: 0.9793\n",
            "Epoch 416/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1558 - val_accuracy: 0.9776 - val_f1: 0.9778\n",
            "Epoch 417/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1498 - val_accuracy: 0.9790 - val_f1: 0.9791\n",
            "Epoch 418/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1468 - val_accuracy: 0.9797 - val_f1: 0.9798\n",
            "Epoch 419/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0021 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1609 - val_accuracy: 0.9768 - val_f1: 0.9770\n",
            "Epoch 420/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1434 - val_accuracy: 0.9793 - val_f1: 0.9793\n",
            "Epoch 421/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1412 - val_accuracy: 0.9793 - val_f1: 0.9793\n",
            "Epoch 422/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1399 - val_accuracy: 0.9792 - val_f1: 0.9791\n",
            "Epoch 423/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1521 - val_accuracy: 0.9780 - val_f1: 0.9781\n",
            "Epoch 424/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1398 - val_accuracy: 0.9803 - val_f1: 0.9803\n",
            "Epoch 425/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1403 - val_accuracy: 0.9803 - val_f1: 0.9803\n",
            "Epoch 426/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1450 - val_accuracy: 0.9802 - val_f1: 0.9802\n",
            "Epoch 427/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0017 - accuracy: 0.9996 - f1: 0.9997 - val_loss: 0.1316 - val_accuracy: 0.9810 - val_f1: 0.9810\n",
            "Epoch 428/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1451 - val_accuracy: 0.9790 - val_f1: 0.9791\n",
            "Epoch 429/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1621 - val_accuracy: 0.9766 - val_f1: 0.9768\n",
            "Epoch 430/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1505 - val_accuracy: 0.9773 - val_f1: 0.9776\n",
            "Epoch 431/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1467 - val_accuracy: 0.9775 - val_f1: 0.9776\n",
            "Epoch 432/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1561 - val_accuracy: 0.9787 - val_f1: 0.9786\n",
            "Epoch 433/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1366 - val_accuracy: 0.9797 - val_f1: 0.9798\n",
            "Epoch 434/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1354 - val_accuracy: 0.9808 - val_f1: 0.9809\n",
            "Epoch 435/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1370 - val_accuracy: 0.9801 - val_f1: 0.9802\n",
            "Epoch 436/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1379 - val_accuracy: 0.9793 - val_f1: 0.9796\n",
            "Epoch 437/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1394 - val_accuracy: 0.9804 - val_f1: 0.9805\n",
            "Epoch 438/1000\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0015 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1467 - val_accuracy: 0.9797 - val_f1: 0.9799\n",
            "Epoch 439/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1355 - val_accuracy: 0.9812 - val_f1: 0.9811\n",
            "Epoch 440/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0021 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1354 - val_accuracy: 0.9810 - val_f1: 0.9809\n",
            "Epoch 441/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1453 - val_accuracy: 0.9797 - val_f1: 0.9798\n",
            "Epoch 442/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1766 - val_accuracy: 0.9773 - val_f1: 0.9774\n",
            "Epoch 443/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0021 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1416 - val_accuracy: 0.9800 - val_f1: 0.9802\n",
            "Epoch 444/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1380 - val_accuracy: 0.9803 - val_f1: 0.9804\n",
            "Epoch 445/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1893 - val_accuracy: 0.9727 - val_f1: 0.9729\n",
            "Epoch 446/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0019 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1458 - val_accuracy: 0.9778 - val_f1: 0.9780\n",
            "Epoch 447/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1447 - val_accuracy: 0.9794 - val_f1: 0.9795\n",
            "Epoch 448/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0014 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1561 - val_accuracy: 0.9793 - val_f1: 0.9792\n",
            "Epoch 449/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1435 - val_accuracy: 0.9812 - val_f1: 0.9812\n",
            "Epoch 450/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9997 - val_loss: 0.1361 - val_accuracy: 0.9788 - val_f1: 0.9790\n",
            "Epoch 451/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0022 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1405 - val_accuracy: 0.9803 - val_f1: 0.9803\n",
            "Epoch 452/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1419 - val_accuracy: 0.9798 - val_f1: 0.9798\n",
            "Epoch 453/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1465 - val_accuracy: 0.9785 - val_f1: 0.9787\n",
            "Epoch 454/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0015 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1731 - val_accuracy: 0.9758 - val_f1: 0.9759\n",
            "Epoch 455/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0019 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1412 - val_accuracy: 0.9783 - val_f1: 0.9784\n",
            "Epoch 456/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1392 - val_accuracy: 0.9797 - val_f1: 0.9797\n",
            "Epoch 457/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0020 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1370 - val_accuracy: 0.9795 - val_f1: 0.9795\n",
            "Epoch 458/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1553 - val_accuracy: 0.9776 - val_f1: 0.9775\n",
            "Epoch 459/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0019 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1450 - val_accuracy: 0.9785 - val_f1: 0.9785\n",
            "Epoch 460/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1379 - val_accuracy: 0.9795 - val_f1: 0.9795\n",
            "Epoch 461/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0021 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1422 - val_accuracy: 0.9801 - val_f1: 0.9801\n",
            "Epoch 462/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0017 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1429 - val_accuracy: 0.9790 - val_f1: 0.9791\n",
            "Epoch 463/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1320 - val_accuracy: 0.9789 - val_f1: 0.9789\n",
            "Epoch 464/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1398 - val_accuracy: 0.9788 - val_f1: 0.9791\n",
            "Epoch 465/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1339 - val_accuracy: 0.9808 - val_f1: 0.9807\n",
            "Epoch 466/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0021 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1441 - val_accuracy: 0.9794 - val_f1: 0.9797\n",
            "Epoch 467/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0021 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1483 - val_accuracy: 0.9791 - val_f1: 0.9792\n",
            "Epoch 468/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1442 - val_accuracy: 0.9793 - val_f1: 0.9794\n",
            "Epoch 469/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0019 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1390 - val_accuracy: 0.9791 - val_f1: 0.9792\n",
            "Epoch 470/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1523 - val_accuracy: 0.9784 - val_f1: 0.9786\n",
            "Epoch 471/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1467 - val_accuracy: 0.9792 - val_f1: 0.9793\n",
            "Epoch 472/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1465 - val_accuracy: 0.9795 - val_f1: 0.9794\n",
            "Epoch 473/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1582 - val_accuracy: 0.9767 - val_f1: 0.9769\n",
            "Epoch 474/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1652 - val_accuracy: 0.9765 - val_f1: 0.9767\n",
            "Epoch 475/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1328 - val_accuracy: 0.9796 - val_f1: 0.9797\n",
            "Epoch 476/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0020 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1394 - val_accuracy: 0.9791 - val_f1: 0.9792\n",
            "Epoch 477/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0020 - accuracy: 0.9998 - f1: 0.9997 - val_loss: 0.1489 - val_accuracy: 0.9788 - val_f1: 0.9789\n",
            "Epoch 478/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1393 - val_accuracy: 0.9784 - val_f1: 0.9786\n",
            "Epoch 479/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1478 - val_accuracy: 0.9788 - val_f1: 0.9788\n",
            "Epoch 480/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0019 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1469 - val_accuracy: 0.9795 - val_f1: 0.9797\n",
            "Epoch 481/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0020 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1406 - val_accuracy: 0.9797 - val_f1: 0.9798\n",
            "Epoch 482/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1620 - val_accuracy: 0.9776 - val_f1: 0.9777\n",
            "Epoch 483/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1479 - val_accuracy: 0.9772 - val_f1: 0.9774\n",
            "Epoch 484/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0019 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1465 - val_accuracy: 0.9783 - val_f1: 0.9783\n",
            "Epoch 485/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1509 - val_accuracy: 0.9772 - val_f1: 0.9773\n",
            "Epoch 486/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0020 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1500 - val_accuracy: 0.9785 - val_f1: 0.9787\n",
            "Epoch 487/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1686 - val_accuracy: 0.9777 - val_f1: 0.9777\n",
            "Epoch 488/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0020 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1546 - val_accuracy: 0.9777 - val_f1: 0.9777\n",
            "Epoch 489/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1436 - val_accuracy: 0.9787 - val_f1: 0.9787\n",
            "Epoch 490/1000\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1570 - val_accuracy: 0.9784 - val_f1: 0.9785\n",
            "Epoch 491/1000\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0014 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1517 - val_accuracy: 0.9778 - val_f1: 0.9778\n",
            "Epoch 492/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1424 - val_accuracy: 0.9787 - val_f1: 0.9789\n",
            "Epoch 493/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1430 - val_accuracy: 0.9796 - val_f1: 0.9797\n",
            "Epoch 494/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1482 - val_accuracy: 0.9787 - val_f1: 0.9787\n",
            "Epoch 495/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1511 - val_accuracy: 0.9775 - val_f1: 0.9776\n",
            "Epoch 496/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1353 - val_accuracy: 0.9803 - val_f1: 0.9803\n",
            "Epoch 497/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1406 - val_accuracy: 0.9778 - val_f1: 0.9778\n",
            "Epoch 498/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1778 - val_accuracy: 0.9744 - val_f1: 0.9744\n",
            "Epoch 499/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1479 - val_accuracy: 0.9783 - val_f1: 0.9785\n",
            "Epoch 500/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0020 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1522 - val_accuracy: 0.9792 - val_f1: 0.9792\n",
            "Epoch 501/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0014 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1657 - val_accuracy: 0.9765 - val_f1: 0.9766\n",
            "Epoch 502/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1493 - val_accuracy: 0.9787 - val_f1: 0.9786\n",
            "Epoch 503/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1413 - val_accuracy: 0.9787 - val_f1: 0.9788\n",
            "Epoch 504/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1479 - val_accuracy: 0.9787 - val_f1: 0.9788\n",
            "Epoch 505/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0014 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1516 - val_accuracy: 0.9783 - val_f1: 0.9783\n",
            "Epoch 506/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0020 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1603 - val_accuracy: 0.9779 - val_f1: 0.9779\n",
            "Epoch 507/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1589 - val_accuracy: 0.9776 - val_f1: 0.9777\n",
            "Epoch 508/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1412 - val_accuracy: 0.9802 - val_f1: 0.9804\n",
            "Epoch 509/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1415 - val_accuracy: 0.9804 - val_f1: 0.9803\n",
            "Epoch 510/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1564 - val_accuracy: 0.9777 - val_f1: 0.9777\n",
            "Epoch 511/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1695 - val_accuracy: 0.9767 - val_f1: 0.9767\n",
            "Epoch 512/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1467 - val_accuracy: 0.9797 - val_f1: 0.9800\n",
            "Epoch 513/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1463 - val_accuracy: 0.9793 - val_f1: 0.9792\n",
            "Epoch 514/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1560 - val_accuracy: 0.9782 - val_f1: 0.9783\n",
            "Epoch 515/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1444 - val_accuracy: 0.9790 - val_f1: 0.9791\n",
            "Epoch 516/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1545 - val_accuracy: 0.9779 - val_f1: 0.9779\n",
            "Epoch 517/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1524 - val_accuracy: 0.9796 - val_f1: 0.9795\n",
            "Epoch 518/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1551 - val_accuracy: 0.9784 - val_f1: 0.9787\n",
            "Epoch 519/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1532 - val_accuracy: 0.9793 - val_f1: 0.9795\n",
            "Epoch 520/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1601 - val_accuracy: 0.9771 - val_f1: 0.9773\n",
            "Epoch 521/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1498 - val_accuracy: 0.9794 - val_f1: 0.9795\n",
            "Epoch 522/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0015 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1559 - val_accuracy: 0.9779 - val_f1: 0.9781\n",
            "Epoch 523/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0020 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1435 - val_accuracy: 0.9791 - val_f1: 0.9791\n",
            "Epoch 524/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1478 - val_accuracy: 0.9793 - val_f1: 0.9794\n",
            "Epoch 525/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1534 - val_accuracy: 0.9789 - val_f1: 0.9790\n",
            "Epoch 526/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0020 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1461 - val_accuracy: 0.9785 - val_f1: 0.9786\n",
            "Epoch 527/1000\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0016 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1532 - val_accuracy: 0.9787 - val_f1: 0.9788\n",
            "Epoch 528/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0020 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1697 - val_accuracy: 0.9777 - val_f1: 0.9778\n",
            "Epoch 529/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1496 - val_accuracy: 0.9802 - val_f1: 0.9801\n",
            "Epoch 530/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1526 - val_accuracy: 0.9795 - val_f1: 0.9796\n",
            "Epoch 531/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0019 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1527 - val_accuracy: 0.9796 - val_f1: 0.9796\n",
            "Epoch 532/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0016 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1568 - val_accuracy: 0.9766 - val_f1: 0.9768\n",
            "Epoch 533/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1475 - val_accuracy: 0.9800 - val_f1: 0.9801\n",
            "Epoch 534/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0012 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1651 - val_accuracy: 0.9766 - val_f1: 0.9765\n",
            "Epoch 535/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1523 - val_accuracy: 0.9787 - val_f1: 0.9787\n",
            "Epoch 536/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0023 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1417 - val_accuracy: 0.9793 - val_f1: 0.9793\n",
            "Epoch 537/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1486 - val_accuracy: 0.9786 - val_f1: 0.9787\n",
            "Epoch 538/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1487 - val_accuracy: 0.9778 - val_f1: 0.9778\n",
            "Epoch 539/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1427 - val_accuracy: 0.9802 - val_f1: 0.9802\n",
            "Epoch 540/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0011 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1452 - val_accuracy: 0.9798 - val_f1: 0.9797\n",
            "Epoch 541/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0016 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1431 - val_accuracy: 0.9797 - val_f1: 0.9796\n",
            "Epoch 542/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0023 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1535 - val_accuracy: 0.9778 - val_f1: 0.9780\n",
            "Epoch 543/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1512 - val_accuracy: 0.9778 - val_f1: 0.9780\n",
            "Epoch 544/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1455 - val_accuracy: 0.9782 - val_f1: 0.9782\n",
            "Epoch 545/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1511 - val_accuracy: 0.9783 - val_f1: 0.9784\n",
            "Epoch 546/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1620 - val_accuracy: 0.9765 - val_f1: 0.9765\n",
            "Epoch 547/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1408 - val_accuracy: 0.9799 - val_f1: 0.9800\n",
            "Epoch 548/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1759 - val_accuracy: 0.9728 - val_f1: 0.9728\n",
            "Epoch 549/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1505 - val_accuracy: 0.9793 - val_f1: 0.9795\n",
            "Epoch 550/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1359 - val_accuracy: 0.9779 - val_f1: 0.9782\n",
            "Epoch 551/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1587 - val_accuracy: 0.9763 - val_f1: 0.9763\n",
            "Epoch 552/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1459 - val_accuracy: 0.9786 - val_f1: 0.9788\n",
            "Epoch 553/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1759 - val_accuracy: 0.9745 - val_f1: 0.9746\n",
            "Epoch 554/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1507 - val_accuracy: 0.9790 - val_f1: 0.9791\n",
            "Epoch 555/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1516 - val_accuracy: 0.9775 - val_f1: 0.9776\n",
            "Epoch 556/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1502 - val_accuracy: 0.9778 - val_f1: 0.9781\n",
            "Epoch 557/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1508 - val_accuracy: 0.9799 - val_f1: 0.9798\n",
            "Epoch 558/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1400 - val_accuracy: 0.9792 - val_f1: 0.9793\n",
            "Epoch 559/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1599 - val_accuracy: 0.9773 - val_f1: 0.9773\n",
            "Epoch 560/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1675 - val_accuracy: 0.9781 - val_f1: 0.9780\n",
            "Epoch 561/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0020 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1669 - val_accuracy: 0.9747 - val_f1: 0.9748\n",
            "Epoch 562/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0021 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1533 - val_accuracy: 0.9789 - val_f1: 0.9790\n",
            "Epoch 563/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1520 - val_accuracy: 0.9779 - val_f1: 0.9780\n",
            "Epoch 564/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1386 - val_accuracy: 0.9788 - val_f1: 0.9789\n",
            "Epoch 565/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0012 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1515 - val_accuracy: 0.9783 - val_f1: 0.9783\n",
            "Epoch 566/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1754 - val_accuracy: 0.9727 - val_f1: 0.9729\n",
            "Epoch 567/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1429 - val_accuracy: 0.9794 - val_f1: 0.9794\n",
            "Epoch 568/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1480 - val_accuracy: 0.9773 - val_f1: 0.9773\n",
            "Epoch 569/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1439 - val_accuracy: 0.9800 - val_f1: 0.9800\n",
            "Epoch 570/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1439 - val_accuracy: 0.9790 - val_f1: 0.9791\n",
            "Epoch 571/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1502 - val_accuracy: 0.9777 - val_f1: 0.9779\n",
            "Epoch 572/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0020 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1462 - val_accuracy: 0.9776 - val_f1: 0.9777\n",
            "Epoch 573/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1529 - val_accuracy: 0.9775 - val_f1: 0.9777\n",
            "Epoch 574/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1577 - val_accuracy: 0.9774 - val_f1: 0.9776\n",
            "Epoch 575/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1421 - val_accuracy: 0.9786 - val_f1: 0.9788\n",
            "Epoch 576/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1379 - val_accuracy: 0.9786 - val_f1: 0.9787\n",
            "Epoch 577/1000\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0019 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1485 - val_accuracy: 0.9783 - val_f1: 0.9783\n",
            "Epoch 578/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0022 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1451 - val_accuracy: 0.9786 - val_f1: 0.9787\n",
            "Epoch 579/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1662 - val_accuracy: 0.9775 - val_f1: 0.9775\n",
            "Epoch 580/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1519 - val_accuracy: 0.9790 - val_f1: 0.9790\n",
            "Epoch 581/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1433 - val_accuracy: 0.9794 - val_f1: 0.9796\n",
            "Epoch 582/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1475 - val_accuracy: 0.9797 - val_f1: 0.9797\n",
            "Epoch 583/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1384 - val_accuracy: 0.9794 - val_f1: 0.9795\n",
            "Epoch 584/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1485 - val_accuracy: 0.9783 - val_f1: 0.9783\n",
            "Epoch 585/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1350 - val_accuracy: 0.9803 - val_f1: 0.9804\n",
            "Epoch 586/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1701 - val_accuracy: 0.9760 - val_f1: 0.9759\n",
            "Epoch 587/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1706 - val_accuracy: 0.9771 - val_f1: 0.9773\n",
            "Epoch 588/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1470 - val_accuracy: 0.9782 - val_f1: 0.9783\n",
            "Epoch 589/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0021 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1676 - val_accuracy: 0.9756 - val_f1: 0.9757\n",
            "Epoch 590/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0020 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1497 - val_accuracy: 0.9777 - val_f1: 0.9779\n",
            "Epoch 591/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1500 - val_accuracy: 0.9782 - val_f1: 0.9782\n",
            "Epoch 592/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1457 - val_accuracy: 0.9784 - val_f1: 0.9784\n",
            "Epoch 593/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1444 - val_accuracy: 0.9799 - val_f1: 0.9801\n",
            "Epoch 594/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1445 - val_accuracy: 0.9794 - val_f1: 0.9794\n",
            "Epoch 595/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1431 - val_accuracy: 0.9788 - val_f1: 0.9790\n",
            "Epoch 596/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1693 - val_accuracy: 0.9748 - val_f1: 0.9748\n",
            "Epoch 597/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1557 - val_accuracy: 0.9782 - val_f1: 0.9784\n",
            "Epoch 598/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1481 - val_accuracy: 0.9793 - val_f1: 0.9794\n",
            "Epoch 599/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1397 - val_accuracy: 0.9799 - val_f1: 0.9799\n",
            "Epoch 600/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9996 - f1: 0.9997 - val_loss: 0.1479 - val_accuracy: 0.9778 - val_f1: 0.9779\n",
            "Epoch 601/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0012 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1426 - val_accuracy: 0.9790 - val_f1: 0.9792\n",
            "Epoch 602/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1321 - val_accuracy: 0.9807 - val_f1: 0.9807\n",
            "Epoch 603/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1495 - val_accuracy: 0.9775 - val_f1: 0.9777\n",
            "Epoch 604/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1442 - val_accuracy: 0.9791 - val_f1: 0.9791\n",
            "Epoch 605/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1498 - val_accuracy: 0.9778 - val_f1: 0.9782\n",
            "Epoch 606/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1542 - val_accuracy: 0.9775 - val_f1: 0.9775\n",
            "Epoch 607/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1408 - val_accuracy: 0.9797 - val_f1: 0.9797\n",
            "Epoch 608/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0026 - accuracy: 0.9994 - f1: 0.9994 - val_loss: 0.1638 - val_accuracy: 0.9768 - val_f1: 0.9769\n",
            "Epoch 609/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1428 - val_accuracy: 0.9781 - val_f1: 0.9783\n",
            "Epoch 610/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0020 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1431 - val_accuracy: 0.9785 - val_f1: 0.9785\n",
            "Epoch 611/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0012 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1386 - val_accuracy: 0.9797 - val_f1: 0.9797\n",
            "Epoch 612/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1600 - val_accuracy: 0.9779 - val_f1: 0.9780\n",
            "Epoch 613/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1645 - val_accuracy: 0.9760 - val_f1: 0.9762\n",
            "Epoch 614/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1448 - val_accuracy: 0.9783 - val_f1: 0.9785\n",
            "Epoch 615/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1464 - val_accuracy: 0.9774 - val_f1: 0.9775\n",
            "Epoch 616/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1395 - val_accuracy: 0.9791 - val_f1: 0.9791\n",
            "Epoch 617/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0012 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1472 - val_accuracy: 0.9786 - val_f1: 0.9787\n",
            "Epoch 618/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0017 - accuracy: 0.9996 - f1: 0.9997 - val_loss: 0.1527 - val_accuracy: 0.9769 - val_f1: 0.9772\n",
            "Epoch 619/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1454 - val_accuracy: 0.9789 - val_f1: 0.9789\n",
            "Epoch 620/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1485 - val_accuracy: 0.9781 - val_f1: 0.9781\n",
            "Epoch 621/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1374 - val_accuracy: 0.9785 - val_f1: 0.9786\n",
            "Epoch 622/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0020 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1487 - val_accuracy: 0.9790 - val_f1: 0.9790\n",
            "Epoch 623/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1435 - val_accuracy: 0.9796 - val_f1: 0.9795\n",
            "Epoch 624/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1415 - val_accuracy: 0.9794 - val_f1: 0.9793\n",
            "Epoch 625/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1399 - val_accuracy: 0.9801 - val_f1: 0.9803\n",
            "Epoch 626/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1610 - val_accuracy: 0.9778 - val_f1: 0.9779\n",
            "Epoch 627/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1483 - val_accuracy: 0.9762 - val_f1: 0.9764\n",
            "Epoch 628/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1636 - val_accuracy: 0.9771 - val_f1: 0.9771\n",
            "Epoch 629/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1512 - val_accuracy: 0.9781 - val_f1: 0.9782\n",
            "Epoch 630/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1554 - val_accuracy: 0.9778 - val_f1: 0.9777\n",
            "Epoch 631/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0012 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1368 - val_accuracy: 0.9796 - val_f1: 0.9797\n",
            "Epoch 632/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1511 - val_accuracy: 0.9783 - val_f1: 0.9783\n",
            "Epoch 633/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1412 - val_accuracy: 0.9796 - val_f1: 0.9798\n",
            "Epoch 634/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1664 - val_accuracy: 0.9783 - val_f1: 0.9784\n",
            "Epoch 635/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1548 - val_accuracy: 0.9794 - val_f1: 0.9794\n",
            "Epoch 636/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1479 - val_accuracy: 0.9800 - val_f1: 0.9801\n",
            "Epoch 637/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1562 - val_accuracy: 0.9791 - val_f1: 0.9790\n",
            "Epoch 638/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0021 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1598 - val_accuracy: 0.9778 - val_f1: 0.9780\n",
            "Epoch 639/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1442 - val_accuracy: 0.9792 - val_f1: 0.9792\n",
            "Epoch 640/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1530 - val_accuracy: 0.9780 - val_f1: 0.9783\n",
            "Epoch 641/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1573 - val_accuracy: 0.9796 - val_f1: 0.9798\n",
            "Epoch 642/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1477 - val_accuracy: 0.9783 - val_f1: 0.9783\n",
            "Epoch 643/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1493 - val_accuracy: 0.9789 - val_f1: 0.9789\n",
            "Epoch 644/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1510 - val_accuracy: 0.9783 - val_f1: 0.9783\n",
            "Epoch 645/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1606 - val_accuracy: 0.9767 - val_f1: 0.9767\n",
            "Epoch 646/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1421 - val_accuracy: 0.9799 - val_f1: 0.9799\n",
            "Epoch 647/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1470 - val_accuracy: 0.9784 - val_f1: 0.9784\n",
            "Epoch 648/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1426 - val_accuracy: 0.9784 - val_f1: 0.9786\n",
            "Epoch 649/1000\n",
            "188/188 [==============================] - 4s 19ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1552 - val_accuracy: 0.9776 - val_f1: 0.9778\n",
            "Epoch 650/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1478 - val_accuracy: 0.9786 - val_f1: 0.9786\n",
            "Epoch 651/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0021 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1608 - val_accuracy: 0.9776 - val_f1: 0.9775\n",
            "Epoch 652/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0011 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1496 - val_accuracy: 0.9785 - val_f1: 0.9785\n",
            "Epoch 653/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1525 - val_accuracy: 0.9783 - val_f1: 0.9783\n",
            "Epoch 654/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1618 - val_accuracy: 0.9778 - val_f1: 0.9778\n",
            "Epoch 655/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0021 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1583 - val_accuracy: 0.9777 - val_f1: 0.9779\n",
            "Epoch 656/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0012 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1602 - val_accuracy: 0.9782 - val_f1: 0.9784\n",
            "Epoch 657/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0020 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1441 - val_accuracy: 0.9783 - val_f1: 0.9784\n",
            "Epoch 658/1000\n",
            "188/188 [==============================] - 4s 19ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1481 - val_accuracy: 0.9788 - val_f1: 0.9789\n",
            "Epoch 659/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1625 - val_accuracy: 0.9762 - val_f1: 0.9762\n",
            "Epoch 660/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1422 - val_accuracy: 0.9795 - val_f1: 0.9798\n",
            "Epoch 661/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1429 - val_accuracy: 0.9801 - val_f1: 0.9803\n",
            "Epoch 662/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0018 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1467 - val_accuracy: 0.9787 - val_f1: 0.9789\n",
            "Epoch 663/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1548 - val_accuracy: 0.9787 - val_f1: 0.9787\n",
            "Epoch 664/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1738 - val_accuracy: 0.9748 - val_f1: 0.9752\n",
            "Epoch 665/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1570 - val_accuracy: 0.9787 - val_f1: 0.9789\n",
            "Epoch 666/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1620 - val_accuracy: 0.9786 - val_f1: 0.9788\n",
            "Epoch 667/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1418 - val_accuracy: 0.9801 - val_f1: 0.9801\n",
            "Epoch 668/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1400 - val_accuracy: 0.9798 - val_f1: 0.9800\n",
            "Epoch 669/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1631 - val_accuracy: 0.9785 - val_f1: 0.9787\n",
            "Epoch 670/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0019 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1493 - val_accuracy: 0.9791 - val_f1: 0.9791\n",
            "Epoch 671/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0019 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1570 - val_accuracy: 0.9778 - val_f1: 0.9781\n",
            "Epoch 672/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0015 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1398 - val_accuracy: 0.9790 - val_f1: 0.9791\n",
            "Epoch 673/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1556 - val_accuracy: 0.9764 - val_f1: 0.9766\n",
            "Epoch 674/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1449 - val_accuracy: 0.9792 - val_f1: 0.9793\n",
            "Epoch 675/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0021 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1503 - val_accuracy: 0.9772 - val_f1: 0.9774\n",
            "Epoch 676/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1408 - val_accuracy: 0.9797 - val_f1: 0.9799\n",
            "Epoch 677/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1341 - val_accuracy: 0.9808 - val_f1: 0.9807\n",
            "Epoch 678/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0014 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1527 - val_accuracy: 0.9784 - val_f1: 0.9785\n",
            "Epoch 679/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1452 - val_accuracy: 0.9787 - val_f1: 0.9790\n",
            "Epoch 680/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0021 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1514 - val_accuracy: 0.9787 - val_f1: 0.9787\n",
            "Epoch 681/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1650 - val_accuracy: 0.9776 - val_f1: 0.9778\n",
            "Epoch 682/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1474 - val_accuracy: 0.9798 - val_f1: 0.9801\n",
            "Epoch 683/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1585 - val_accuracy: 0.9772 - val_f1: 0.9773\n",
            "Epoch 684/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1684 - val_accuracy: 0.9772 - val_f1: 0.9772\n",
            "Epoch 685/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1474 - val_accuracy: 0.9788 - val_f1: 0.9790\n",
            "Epoch 686/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1602 - val_accuracy: 0.9764 - val_f1: 0.9764\n",
            "Epoch 687/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0023 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1395 - val_accuracy: 0.9792 - val_f1: 0.9793\n",
            "Epoch 688/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1507 - val_accuracy: 0.9781 - val_f1: 0.9781\n",
            "Epoch 689/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1462 - val_accuracy: 0.9784 - val_f1: 0.9785\n",
            "Epoch 690/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0021 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1445 - val_accuracy: 0.9793 - val_f1: 0.9793\n",
            "Epoch 691/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1507 - val_accuracy: 0.9789 - val_f1: 0.9787\n",
            "Epoch 692/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1437 - val_accuracy: 0.9786 - val_f1: 0.9786\n",
            "Epoch 693/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0011 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1485 - val_accuracy: 0.9783 - val_f1: 0.9782\n",
            "Epoch 694/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9997 - val_loss: 0.1808 - val_accuracy: 0.9741 - val_f1: 0.9740\n",
            "Epoch 695/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1798 - val_accuracy: 0.9760 - val_f1: 0.9762\n",
            "Epoch 696/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1441 - val_accuracy: 0.9796 - val_f1: 0.9797\n",
            "Epoch 697/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1440 - val_accuracy: 0.9800 - val_f1: 0.9801\n",
            "Epoch 698/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1487 - val_accuracy: 0.9781 - val_f1: 0.9782\n",
            "Epoch 699/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1492 - val_accuracy: 0.9792 - val_f1: 0.9792\n",
            "Epoch 700/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1611 - val_accuracy: 0.9753 - val_f1: 0.9756\n",
            "Epoch 701/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1492 - val_accuracy: 0.9780 - val_f1: 0.9783\n",
            "Epoch 702/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1403 - val_accuracy: 0.9789 - val_f1: 0.9792\n",
            "Epoch 703/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1619 - val_accuracy: 0.9775 - val_f1: 0.9776\n",
            "Epoch 704/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1428 - val_accuracy: 0.9788 - val_f1: 0.9789\n",
            "Epoch 705/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1462 - val_accuracy: 0.9791 - val_f1: 0.9792\n",
            "Epoch 706/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0015 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1393 - val_accuracy: 0.9791 - val_f1: 0.9792\n",
            "Epoch 707/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0020 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1465 - val_accuracy: 0.9787 - val_f1: 0.9788\n",
            "Epoch 708/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0012 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1445 - val_accuracy: 0.9793 - val_f1: 0.9792\n",
            "Epoch 709/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1447 - val_accuracy: 0.9785 - val_f1: 0.9786\n",
            "Epoch 710/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1316 - val_accuracy: 0.9797 - val_f1: 0.9799\n",
            "Epoch 711/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0019 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1672 - val_accuracy: 0.9740 - val_f1: 0.9742\n",
            "Epoch 712/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1719 - val_accuracy: 0.9757 - val_f1: 0.9757\n",
            "Epoch 713/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1455 - val_accuracy: 0.9784 - val_f1: 0.9787\n",
            "Epoch 714/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1515 - val_accuracy: 0.9800 - val_f1: 0.9799\n",
            "Epoch 715/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1547 - val_accuracy: 0.9785 - val_f1: 0.9787\n",
            "Epoch 716/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1609 - val_accuracy: 0.9766 - val_f1: 0.9768\n",
            "Epoch 717/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1541 - val_accuracy: 0.9787 - val_f1: 0.9787\n",
            "Epoch 718/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1441 - val_accuracy: 0.9780 - val_f1: 0.9783\n",
            "Epoch 719/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1539 - val_accuracy: 0.9783 - val_f1: 0.9782\n",
            "Epoch 720/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1537 - val_accuracy: 0.9787 - val_f1: 0.9789\n",
            "Epoch 721/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1504 - val_accuracy: 0.9783 - val_f1: 0.9786\n",
            "Epoch 722/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1486 - val_accuracy: 0.9794 - val_f1: 0.9796\n",
            "Epoch 723/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1510 - val_accuracy: 0.9797 - val_f1: 0.9797\n",
            "Epoch 724/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1539 - val_accuracy: 0.9782 - val_f1: 0.9783\n",
            "Epoch 725/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1592 - val_accuracy: 0.9763 - val_f1: 0.9765\n",
            "Epoch 726/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1564 - val_accuracy: 0.9769 - val_f1: 0.9772\n",
            "Epoch 727/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1462 - val_accuracy: 0.9794 - val_f1: 0.9796\n",
            "Epoch 728/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1478 - val_accuracy: 0.9789 - val_f1: 0.9790\n",
            "Epoch 729/1000\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0016 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1587 - val_accuracy: 0.9774 - val_f1: 0.9777\n",
            "Epoch 730/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1579 - val_accuracy: 0.9787 - val_f1: 0.9790\n",
            "Epoch 731/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1481 - val_accuracy: 0.9791 - val_f1: 0.9792\n",
            "Epoch 732/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1473 - val_accuracy: 0.9792 - val_f1: 0.9793\n",
            "Epoch 733/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1727 - val_accuracy: 0.9774 - val_f1: 0.9776\n",
            "Epoch 734/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1530 - val_accuracy: 0.9784 - val_f1: 0.9787\n",
            "Epoch 735/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1422 - val_accuracy: 0.9798 - val_f1: 0.9799\n",
            "Epoch 736/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1449 - val_accuracy: 0.9799 - val_f1: 0.9799\n",
            "Epoch 737/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1475 - val_accuracy: 0.9781 - val_f1: 0.9782\n",
            "Epoch 738/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1559 - val_accuracy: 0.9777 - val_f1: 0.9778\n",
            "Epoch 739/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1477 - val_accuracy: 0.9782 - val_f1: 0.9784\n",
            "Epoch 740/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1504 - val_accuracy: 0.9785 - val_f1: 0.9788\n",
            "Epoch 741/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1588 - val_accuracy: 0.9786 - val_f1: 0.9787\n",
            "Epoch 742/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1687 - val_accuracy: 0.9760 - val_f1: 0.9761\n",
            "Epoch 743/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1578 - val_accuracy: 0.9773 - val_f1: 0.9774\n",
            "Epoch 744/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9997 - val_loss: 0.1878 - val_accuracy: 0.9760 - val_f1: 0.9760\n",
            "Epoch 745/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0020 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1465 - val_accuracy: 0.9768 - val_f1: 0.9769\n",
            "Epoch 746/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1452 - val_accuracy: 0.9781 - val_f1: 0.9783\n",
            "Epoch 747/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1435 - val_accuracy: 0.9793 - val_f1: 0.9795\n",
            "Epoch 748/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1515 - val_accuracy: 0.9786 - val_f1: 0.9788\n",
            "Epoch 749/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1658 - val_accuracy: 0.9781 - val_f1: 0.9782\n",
            "Epoch 750/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1565 - val_accuracy: 0.9771 - val_f1: 0.9773\n",
            "Epoch 751/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1762 - val_accuracy: 0.9758 - val_f1: 0.9760\n",
            "Epoch 752/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0011 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1699 - val_accuracy: 0.9751 - val_f1: 0.9752\n",
            "Epoch 753/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1519 - val_accuracy: 0.9776 - val_f1: 0.9780\n",
            "Epoch 754/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1570 - val_accuracy: 0.9766 - val_f1: 0.9768\n",
            "Epoch 755/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1440 - val_accuracy: 0.9786 - val_f1: 0.9789\n",
            "Epoch 756/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0012 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1452 - val_accuracy: 0.9794 - val_f1: 0.9794\n",
            "Epoch 757/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9997 - val_loss: 0.1677 - val_accuracy: 0.9764 - val_f1: 0.9766\n",
            "Epoch 758/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1514 - val_accuracy: 0.9787 - val_f1: 0.9786\n",
            "Epoch 759/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1450 - val_accuracy: 0.9782 - val_f1: 0.9783\n",
            "Epoch 760/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0012 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1502 - val_accuracy: 0.9780 - val_f1: 0.9780\n",
            "Epoch 761/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1654 - val_accuracy: 0.9748 - val_f1: 0.9749\n",
            "Epoch 762/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0012 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1521 - val_accuracy: 0.9792 - val_f1: 0.9791\n",
            "Epoch 763/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1423 - val_accuracy: 0.9789 - val_f1: 0.9790\n",
            "Epoch 764/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1565 - val_accuracy: 0.9785 - val_f1: 0.9787\n",
            "Epoch 765/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1547 - val_accuracy: 0.9786 - val_f1: 0.9787\n",
            "Epoch 766/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1602 - val_accuracy: 0.9791 - val_f1: 0.9793\n",
            "Epoch 767/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1522 - val_accuracy: 0.9776 - val_f1: 0.9777\n",
            "Epoch 768/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0012 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1463 - val_accuracy: 0.9794 - val_f1: 0.9795\n",
            "Epoch 769/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1359 - val_accuracy: 0.9808 - val_f1: 0.9806\n",
            "Epoch 770/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1646 - val_accuracy: 0.9779 - val_f1: 0.9782\n",
            "Epoch 771/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0020 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1446 - val_accuracy: 0.9782 - val_f1: 0.9780\n",
            "Epoch 772/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0012 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1717 - val_accuracy: 0.9760 - val_f1: 0.9761\n",
            "Epoch 773/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1484 - val_accuracy: 0.9792 - val_f1: 0.9793\n",
            "Epoch 774/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1563 - val_accuracy: 0.9771 - val_f1: 0.9773\n",
            "Epoch 775/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0020 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1462 - val_accuracy: 0.9786 - val_f1: 0.9786\n",
            "Epoch 776/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1576 - val_accuracy: 0.9767 - val_f1: 0.9769\n",
            "Epoch 777/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1536 - val_accuracy: 0.9777 - val_f1: 0.9779\n",
            "Epoch 778/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1512 - val_accuracy: 0.9777 - val_f1: 0.9777\n",
            "Epoch 779/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9999 - f1: 0.9998 - val_loss: 0.1543 - val_accuracy: 0.9781 - val_f1: 0.9782\n",
            "Epoch 780/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1401 - val_accuracy: 0.9794 - val_f1: 0.9794\n",
            "Epoch 781/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1538 - val_accuracy: 0.9782 - val_f1: 0.9784\n",
            "Epoch 782/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9999 - f1: 0.9998 - val_loss: 0.1475 - val_accuracy: 0.9781 - val_f1: 0.9781\n",
            "Epoch 783/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1440 - val_accuracy: 0.9793 - val_f1: 0.9794\n",
            "Epoch 784/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1422 - val_accuracy: 0.9787 - val_f1: 0.9788\n",
            "Epoch 785/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1398 - val_accuracy: 0.9790 - val_f1: 0.9790\n",
            "Epoch 786/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1678 - val_accuracy: 0.9768 - val_f1: 0.9769\n",
            "Epoch 787/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1396 - val_accuracy: 0.9812 - val_f1: 0.9811\n",
            "Epoch 788/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0021 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1441 - val_accuracy: 0.9780 - val_f1: 0.9781\n",
            "Epoch 789/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1425 - val_accuracy: 0.9793 - val_f1: 0.9794\n",
            "Epoch 790/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0011 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1476 - val_accuracy: 0.9793 - val_f1: 0.9794\n",
            "Epoch 791/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1573 - val_accuracy: 0.9767 - val_f1: 0.9768\n",
            "Epoch 792/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1493 - val_accuracy: 0.9778 - val_f1: 0.9776\n",
            "Epoch 793/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1512 - val_accuracy: 0.9792 - val_f1: 0.9791\n",
            "Epoch 794/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1373 - val_accuracy: 0.9790 - val_f1: 0.9792\n",
            "Epoch 795/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1529 - val_accuracy: 0.9779 - val_f1: 0.9781\n",
            "Epoch 796/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1383 - val_accuracy: 0.9798 - val_f1: 0.9798\n",
            "Epoch 797/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1466 - val_accuracy: 0.9787 - val_f1: 0.9789\n",
            "Epoch 798/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9998 - val_loss: 0.1815 - val_accuracy: 0.9749 - val_f1: 0.9748\n",
            "Epoch 799/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1536 - val_accuracy: 0.9789 - val_f1: 0.9791\n",
            "Epoch 800/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1539 - val_accuracy: 0.9779 - val_f1: 0.9781\n",
            "Epoch 801/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1390 - val_accuracy: 0.9801 - val_f1: 0.9804\n",
            "Epoch 802/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0012 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1396 - val_accuracy: 0.9789 - val_f1: 0.9790\n",
            "Epoch 803/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1380 - val_accuracy: 0.9794 - val_f1: 0.9795\n",
            "Epoch 804/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1567 - val_accuracy: 0.9782 - val_f1: 0.9783\n",
            "Epoch 805/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1365 - val_accuracy: 0.9797 - val_f1: 0.9797\n",
            "Epoch 806/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1354 - val_accuracy: 0.9796 - val_f1: 0.9796\n",
            "Epoch 807/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1370 - val_accuracy: 0.9792 - val_f1: 0.9793\n",
            "Epoch 808/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1432 - val_accuracy: 0.9783 - val_f1: 0.9784\n",
            "Epoch 809/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1357 - val_accuracy: 0.9793 - val_f1: 0.9793\n",
            "Epoch 810/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1421 - val_accuracy: 0.9777 - val_f1: 0.9780\n",
            "Epoch 811/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1647 - val_accuracy: 0.9754 - val_f1: 0.9756\n",
            "Epoch 812/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1482 - val_accuracy: 0.9784 - val_f1: 0.9785\n",
            "Epoch 813/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0011 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1443 - val_accuracy: 0.9796 - val_f1: 0.9797\n",
            "Epoch 814/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1426 - val_accuracy: 0.9792 - val_f1: 0.9792\n",
            "Epoch 815/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0010 - accuracy: 1.0000 - f1: 1.0000 - val_loss: 0.1498 - val_accuracy: 0.9778 - val_f1: 0.9779\n",
            "Epoch 816/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1452 - val_accuracy: 0.9793 - val_f1: 0.9794\n",
            "Epoch 817/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1525 - val_accuracy: 0.9779 - val_f1: 0.9780\n",
            "Epoch 818/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0020 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1481 - val_accuracy: 0.9784 - val_f1: 0.9785\n",
            "Epoch 819/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1546 - val_accuracy: 0.9777 - val_f1: 0.9778\n",
            "Epoch 820/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1567 - val_accuracy: 0.9776 - val_f1: 0.9776\n",
            "Epoch 821/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1393 - val_accuracy: 0.9788 - val_f1: 0.9788\n",
            "Epoch 822/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1449 - val_accuracy: 0.9790 - val_f1: 0.9790\n",
            "Epoch 823/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1405 - val_accuracy: 0.9790 - val_f1: 0.9792\n",
            "Epoch 824/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1479 - val_accuracy: 0.9795 - val_f1: 0.9795\n",
            "Epoch 825/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1391 - val_accuracy: 0.9801 - val_f1: 0.9802\n",
            "Epoch 826/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1379 - val_accuracy: 0.9796 - val_f1: 0.9797\n",
            "Epoch 827/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1429 - val_accuracy: 0.9792 - val_f1: 0.9794\n",
            "Epoch 828/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1448 - val_accuracy: 0.9790 - val_f1: 0.9791\n",
            "Epoch 829/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0019 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1395 - val_accuracy: 0.9791 - val_f1: 0.9792\n",
            "Epoch 830/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1471 - val_accuracy: 0.9788 - val_f1: 0.9789\n",
            "Epoch 831/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1408 - val_accuracy: 0.9787 - val_f1: 0.9788\n",
            "Epoch 832/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0020 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1404 - val_accuracy: 0.9783 - val_f1: 0.9784\n",
            "Epoch 833/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1392 - val_accuracy: 0.9797 - val_f1: 0.9797\n",
            "Epoch 834/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1497 - val_accuracy: 0.9778 - val_f1: 0.9778\n",
            "Epoch 835/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1470 - val_accuracy: 0.9768 - val_f1: 0.9768\n",
            "Epoch 836/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1351 - val_accuracy: 0.9797 - val_f1: 0.9800\n",
            "Epoch 837/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0012 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1552 - val_accuracy: 0.9779 - val_f1: 0.9781\n",
            "Epoch 838/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1862 - val_accuracy: 0.9744 - val_f1: 0.9745\n",
            "Epoch 839/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1460 - val_accuracy: 0.9783 - val_f1: 0.9785\n",
            "Epoch 840/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1594 - val_accuracy: 0.9768 - val_f1: 0.9768\n",
            "Epoch 841/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1642 - val_accuracy: 0.9764 - val_f1: 0.9766\n",
            "Epoch 842/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1438 - val_accuracy: 0.9791 - val_f1: 0.9791\n",
            "Epoch 843/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1427 - val_accuracy: 0.9778 - val_f1: 0.9779\n",
            "Epoch 844/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1414 - val_accuracy: 0.9786 - val_f1: 0.9787\n",
            "Epoch 845/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1452 - val_accuracy: 0.9780 - val_f1: 0.9783\n",
            "Epoch 846/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1391 - val_accuracy: 0.9801 - val_f1: 0.9801\n",
            "Epoch 847/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1505 - val_accuracy: 0.9783 - val_f1: 0.9782\n",
            "Epoch 848/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1337 - val_accuracy: 0.9791 - val_f1: 0.9791\n",
            "Epoch 849/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1404 - val_accuracy: 0.9778 - val_f1: 0.9780\n",
            "Epoch 850/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1539 - val_accuracy: 0.9772 - val_f1: 0.9773\n",
            "Epoch 851/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1438 - val_accuracy: 0.9784 - val_f1: 0.9786\n",
            "Epoch 852/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0011 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1360 - val_accuracy: 0.9787 - val_f1: 0.9787\n",
            "Epoch 853/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1369 - val_accuracy: 0.9785 - val_f1: 0.9786\n",
            "Epoch 854/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1354 - val_accuracy: 0.9787 - val_f1: 0.9787\n",
            "Epoch 855/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0020 - accuracy: 0.9996 - f1: 0.9997 - val_loss: 0.1415 - val_accuracy: 0.9790 - val_f1: 0.9790\n",
            "Epoch 856/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1636 - val_accuracy: 0.9778 - val_f1: 0.9780\n",
            "Epoch 857/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1428 - val_accuracy: 0.9787 - val_f1: 0.9791\n",
            "Epoch 858/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1416 - val_accuracy: 0.9786 - val_f1: 0.9787\n",
            "Epoch 859/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0020 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1411 - val_accuracy: 0.9794 - val_f1: 0.9795\n",
            "Epoch 860/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1328 - val_accuracy: 0.9792 - val_f1: 0.9792\n",
            "Epoch 861/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1366 - val_accuracy: 0.9788 - val_f1: 0.9789\n",
            "Epoch 862/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1756 - val_accuracy: 0.9753 - val_f1: 0.9754\n",
            "Epoch 863/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1350 - val_accuracy: 0.9783 - val_f1: 0.9784\n",
            "Epoch 864/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1495 - val_accuracy: 0.9762 - val_f1: 0.9764\n",
            "Epoch 865/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0020 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1332 - val_accuracy: 0.9793 - val_f1: 0.9792\n",
            "Epoch 866/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1437 - val_accuracy: 0.9783 - val_f1: 0.9784\n",
            "Epoch 867/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1432 - val_accuracy: 0.9778 - val_f1: 0.9779\n",
            "Epoch 868/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1566 - val_accuracy: 0.9770 - val_f1: 0.9772\n",
            "Epoch 869/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1450 - val_accuracy: 0.9779 - val_f1: 0.9782\n",
            "Epoch 870/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0012 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1400 - val_accuracy: 0.9792 - val_f1: 0.9790\n",
            "Epoch 871/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1584 - val_accuracy: 0.9770 - val_f1: 0.9770\n",
            "Epoch 872/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1457 - val_accuracy: 0.9789 - val_f1: 0.9789\n",
            "Epoch 873/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1444 - val_accuracy: 0.9779 - val_f1: 0.9780\n",
            "Epoch 874/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0022 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1483 - val_accuracy: 0.9785 - val_f1: 0.9785\n",
            "Epoch 875/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1429 - val_accuracy: 0.9786 - val_f1: 0.9787\n",
            "Epoch 876/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1470 - val_accuracy: 0.9778 - val_f1: 0.9781\n",
            "Epoch 877/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1412 - val_accuracy: 0.9782 - val_f1: 0.9783\n",
            "Epoch 878/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0011 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1410 - val_accuracy: 0.9796 - val_f1: 0.9797\n",
            "Epoch 879/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1471 - val_accuracy: 0.9783 - val_f1: 0.9784\n",
            "Epoch 880/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0010 - accuracy: 1.0000 - f1: 1.0000 - val_loss: 0.1491 - val_accuracy: 0.9787 - val_f1: 0.9788\n",
            "Epoch 881/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1594 - val_accuracy: 0.9779 - val_f1: 0.9781\n",
            "Epoch 882/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1562 - val_accuracy: 0.9787 - val_f1: 0.9789\n",
            "Epoch 883/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1472 - val_accuracy: 0.9790 - val_f1: 0.9791\n",
            "Epoch 884/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1484 - val_accuracy: 0.9775 - val_f1: 0.9777\n",
            "Epoch 885/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1486 - val_accuracy: 0.9792 - val_f1: 0.9792\n",
            "Epoch 886/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1612 - val_accuracy: 0.9773 - val_f1: 0.9774\n",
            "Epoch 887/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1375 - val_accuracy: 0.9812 - val_f1: 0.9813\n",
            "Epoch 888/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1414 - val_accuracy: 0.9783 - val_f1: 0.9784\n",
            "Epoch 889/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1320 - val_accuracy: 0.9801 - val_f1: 0.9800\n",
            "Epoch 890/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0021 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1441 - val_accuracy: 0.9785 - val_f1: 0.9786\n",
            "Epoch 891/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0012 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1483 - val_accuracy: 0.9780 - val_f1: 0.9780\n",
            "Epoch 892/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1364 - val_accuracy: 0.9802 - val_f1: 0.9803\n",
            "Epoch 893/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1545 - val_accuracy: 0.9774 - val_f1: 0.9777\n",
            "Epoch 894/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0012 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1417 - val_accuracy: 0.9797 - val_f1: 0.9797\n",
            "Epoch 895/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0012 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1424 - val_accuracy: 0.9783 - val_f1: 0.9783\n",
            "Epoch 896/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1480 - val_accuracy: 0.9784 - val_f1: 0.9786\n",
            "Epoch 897/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1522 - val_accuracy: 0.9786 - val_f1: 0.9787\n",
            "Epoch 898/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9997 - val_loss: 0.1646 - val_accuracy: 0.9764 - val_f1: 0.9766\n",
            "Epoch 899/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1504 - val_accuracy: 0.9775 - val_f1: 0.9777\n",
            "Epoch 900/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1473 - val_accuracy: 0.9773 - val_f1: 0.9774\n",
            "Epoch 901/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1559 - val_accuracy: 0.9769 - val_f1: 0.9770\n",
            "Epoch 902/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0012 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1363 - val_accuracy: 0.9788 - val_f1: 0.9788\n",
            "Epoch 903/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9997 - val_loss: 0.1505 - val_accuracy: 0.9775 - val_f1: 0.9776\n",
            "Epoch 904/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0012 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1465 - val_accuracy: 0.9787 - val_f1: 0.9788\n",
            "Epoch 905/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1400 - val_accuracy: 0.9797 - val_f1: 0.9797\n",
            "Epoch 906/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0020 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1425 - val_accuracy: 0.9790 - val_f1: 0.9791\n",
            "Epoch 907/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1493 - val_accuracy: 0.9773 - val_f1: 0.9775\n",
            "Epoch 908/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1451 - val_accuracy: 0.9791 - val_f1: 0.9792\n",
            "Epoch 909/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1461 - val_accuracy: 0.9795 - val_f1: 0.9794\n",
            "Epoch 910/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1369 - val_accuracy: 0.9797 - val_f1: 0.9796\n",
            "Epoch 911/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1775 - val_accuracy: 0.9747 - val_f1: 0.9748\n",
            "Epoch 912/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1524 - val_accuracy: 0.9787 - val_f1: 0.9789\n",
            "Epoch 913/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1355 - val_accuracy: 0.9798 - val_f1: 0.9799\n",
            "Epoch 914/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1541 - val_accuracy: 0.9781 - val_f1: 0.9781\n",
            "Epoch 915/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1494 - val_accuracy: 0.9783 - val_f1: 0.9785\n",
            "Epoch 916/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1511 - val_accuracy: 0.9780 - val_f1: 0.9779\n",
            "Epoch 917/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0022 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1419 - val_accuracy: 0.9787 - val_f1: 0.9788\n",
            "Epoch 918/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0012 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1473 - val_accuracy: 0.9794 - val_f1: 0.9796\n",
            "Epoch 919/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0011 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1422 - val_accuracy: 0.9786 - val_f1: 0.9787\n",
            "Epoch 920/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1419 - val_accuracy: 0.9802 - val_f1: 0.9804\n",
            "Epoch 921/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1442 - val_accuracy: 0.9793 - val_f1: 0.9793\n",
            "Epoch 922/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0026 - accuracy: 0.9996 - f1: 0.9997 - val_loss: 0.1425 - val_accuracy: 0.9783 - val_f1: 0.9785\n",
            "Epoch 923/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1475 - val_accuracy: 0.9790 - val_f1: 0.9790\n",
            "Epoch 924/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1501 - val_accuracy: 0.9783 - val_f1: 0.9784\n",
            "Epoch 925/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1511 - val_accuracy: 0.9778 - val_f1: 0.9777\n",
            "Epoch 926/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1493 - val_accuracy: 0.9753 - val_f1: 0.9756\n",
            "Epoch 927/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1621 - val_accuracy: 0.9770 - val_f1: 0.9772\n",
            "Epoch 928/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1432 - val_accuracy: 0.9789 - val_f1: 0.9789\n",
            "Epoch 929/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0020 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1437 - val_accuracy: 0.9797 - val_f1: 0.9796\n",
            "Epoch 930/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0010 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1425 - val_accuracy: 0.9769 - val_f1: 0.9772\n",
            "Epoch 931/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0023 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1428 - val_accuracy: 0.9784 - val_f1: 0.9783\n",
            "Epoch 932/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0012 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1393 - val_accuracy: 0.9796 - val_f1: 0.9796\n",
            "Epoch 933/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1565 - val_accuracy: 0.9782 - val_f1: 0.9783\n",
            "Epoch 934/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0012 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1370 - val_accuracy: 0.9786 - val_f1: 0.9785\n",
            "Epoch 935/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1401 - val_accuracy: 0.9790 - val_f1: 0.9792\n",
            "Epoch 936/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0020 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1448 - val_accuracy: 0.9783 - val_f1: 0.9786\n",
            "Epoch 937/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1563 - val_accuracy: 0.9760 - val_f1: 0.9761\n",
            "Epoch 938/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1595 - val_accuracy: 0.9768 - val_f1: 0.9772\n",
            "Epoch 939/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1387 - val_accuracy: 0.9778 - val_f1: 0.9780\n",
            "Epoch 940/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1481 - val_accuracy: 0.9772 - val_f1: 0.9772\n",
            "Epoch 941/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1406 - val_accuracy: 0.9778 - val_f1: 0.9779\n",
            "Epoch 942/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1383 - val_accuracy: 0.9797 - val_f1: 0.9799\n",
            "Epoch 943/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1550 - val_accuracy: 0.9774 - val_f1: 0.9776\n",
            "Epoch 944/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0012 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1341 - val_accuracy: 0.9797 - val_f1: 0.9797\n",
            "Epoch 945/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1371 - val_accuracy: 0.9781 - val_f1: 0.9781\n",
            "Epoch 946/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1429 - val_accuracy: 0.9787 - val_f1: 0.9788\n",
            "Epoch 947/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1422 - val_accuracy: 0.9788 - val_f1: 0.9789\n",
            "Epoch 948/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1312 - val_accuracy: 0.9788 - val_f1: 0.9789\n",
            "Epoch 949/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1536 - val_accuracy: 0.9761 - val_f1: 0.9763\n",
            "Epoch 950/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1440 - val_accuracy: 0.9783 - val_f1: 0.9782\n",
            "Epoch 951/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1459 - val_accuracy: 0.9797 - val_f1: 0.9797\n",
            "Epoch 952/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0012 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1464 - val_accuracy: 0.9787 - val_f1: 0.9788\n",
            "Epoch 953/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1410 - val_accuracy: 0.9783 - val_f1: 0.9784\n",
            "Epoch 954/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0012 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1360 - val_accuracy: 0.9783 - val_f1: 0.9783\n",
            "Epoch 955/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1471 - val_accuracy: 0.9783 - val_f1: 0.9783\n",
            "Epoch 956/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1390 - val_accuracy: 0.9791 - val_f1: 0.9790\n",
            "Epoch 957/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0015 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1406 - val_accuracy: 0.9787 - val_f1: 0.9788\n",
            "Epoch 958/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1751 - val_accuracy: 0.9752 - val_f1: 0.9751\n",
            "Epoch 959/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1410 - val_accuracy: 0.9784 - val_f1: 0.9787\n",
            "Epoch 960/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1444 - val_accuracy: 0.9782 - val_f1: 0.9783\n",
            "Epoch 961/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0012 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1455 - val_accuracy: 0.9782 - val_f1: 0.9784\n",
            "Epoch 962/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1392 - val_accuracy: 0.9796 - val_f1: 0.9795\n",
            "Epoch 963/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1413 - val_accuracy: 0.9794 - val_f1: 0.9797\n",
            "Epoch 964/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0012 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1697 - val_accuracy: 0.9748 - val_f1: 0.9749\n",
            "Epoch 965/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1448 - val_accuracy: 0.9783 - val_f1: 0.9782\n",
            "Epoch 966/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1460 - val_accuracy: 0.9802 - val_f1: 0.9801\n",
            "Epoch 967/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1443 - val_accuracy: 0.9791 - val_f1: 0.9791\n",
            "Epoch 968/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0020 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1556 - val_accuracy: 0.9768 - val_f1: 0.9769\n",
            "Epoch 969/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1394 - val_accuracy: 0.9789 - val_f1: 0.9791\n",
            "Epoch 970/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0012 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1368 - val_accuracy: 0.9794 - val_f1: 0.9795\n",
            "Epoch 971/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1372 - val_accuracy: 0.9804 - val_f1: 0.9806\n",
            "Epoch 972/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1370 - val_accuracy: 0.9797 - val_f1: 0.9797\n",
            "Epoch 973/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0012 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1472 - val_accuracy: 0.9801 - val_f1: 0.9800\n",
            "Epoch 974/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0021 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1366 - val_accuracy: 0.9790 - val_f1: 0.9792\n",
            "Epoch 975/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1443 - val_accuracy: 0.9797 - val_f1: 0.9798\n",
            "Epoch 976/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1351 - val_accuracy: 0.9797 - val_f1: 0.9799\n",
            "Epoch 977/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1389 - val_accuracy: 0.9803 - val_f1: 0.9803\n",
            "Epoch 978/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1444 - val_accuracy: 0.9787 - val_f1: 0.9788\n",
            "Epoch 979/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1427 - val_accuracy: 0.9792 - val_f1: 0.9793\n",
            "Epoch 980/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1591 - val_accuracy: 0.9762 - val_f1: 0.9763\n",
            "Epoch 981/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1526 - val_accuracy: 0.9788 - val_f1: 0.9788\n",
            "Epoch 982/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1480 - val_accuracy: 0.9788 - val_f1: 0.9791\n",
            "Epoch 983/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0012 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1598 - val_accuracy: 0.9764 - val_f1: 0.9766\n",
            "Epoch 984/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1405 - val_accuracy: 0.9800 - val_f1: 0.9801\n",
            "Epoch 985/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0013 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1378 - val_accuracy: 0.9797 - val_f1: 0.9799\n",
            "Epoch 986/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0015 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1437 - val_accuracy: 0.9788 - val_f1: 0.9789\n",
            "Epoch 987/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1376 - val_accuracy: 0.9794 - val_f1: 0.9796\n",
            "Epoch 988/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1541 - val_accuracy: 0.9783 - val_f1: 0.9785\n",
            "Epoch 989/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1496 - val_accuracy: 0.9772 - val_f1: 0.9771\n",
            "Epoch 990/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1358 - val_accuracy: 0.9793 - val_f1: 0.9793\n",
            "Epoch 991/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1556 - val_accuracy: 0.9747 - val_f1: 0.9748\n",
            "Epoch 992/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0013 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1468 - val_accuracy: 0.9790 - val_f1: 0.9792\n",
            "Epoch 993/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1422 - val_accuracy: 0.9783 - val_f1: 0.9784\n",
            "Epoch 994/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1500 - val_accuracy: 0.9780 - val_f1: 0.9782\n",
            "Epoch 995/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0012 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1451 - val_accuracy: 0.9773 - val_f1: 0.9776\n",
            "Epoch 996/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1356 - val_accuracy: 0.9801 - val_f1: 0.9801\n",
            "Epoch 997/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1521 - val_accuracy: 0.9781 - val_f1: 0.9783\n",
            "Epoch 998/1000\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1529 - val_accuracy: 0.9770 - val_f1: 0.9773\n",
            "Epoch 999/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0012 - accuracy: 0.9999 - f1: 0.9999 - val_loss: 0.1407 - val_accuracy: 0.9799 - val_f1: 0.9800\n",
            "Epoch 1000/1000\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - accuracy: 0.9998 - f1: 0.9998 - val_loss: 0.1417 - val_accuracy: 0.9791 - val_f1: 0.9790\n",
            "The optimal number of epochs is 87\n",
            "Epoch 1/87\n",
            "188/188 [==============================] - 5s 24ms/step - loss: 0.3665 - accuracy: 0.8909 - f1: 0.8762 - val_loss: 0.1754 - val_accuracy: 0.9491 - val_f1: 0.9490\n",
            "Epoch 2/87\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.1481 - accuracy: 0.9549 - f1: 0.9556 - val_loss: 0.1355 - val_accuracy: 0.9599 - val_f1: 0.9601\n",
            "Epoch 3/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.1012 - accuracy: 0.9697 - f1: 0.9700 - val_loss: 0.1413 - val_accuracy: 0.9565 - val_f1: 0.9573\n",
            "Epoch 4/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0736 - accuracy: 0.9778 - f1: 0.9779 - val_loss: 0.1025 - val_accuracy: 0.9703 - val_f1: 0.9702\n",
            "Epoch 5/87\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0574 - accuracy: 0.9825 - f1: 0.9828 - val_loss: 0.1006 - val_accuracy: 0.9709 - val_f1: 0.9707\n",
            "Epoch 6/87\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0444 - accuracy: 0.9869 - f1: 0.9871 - val_loss: 0.1057 - val_accuracy: 0.9707 - val_f1: 0.9705\n",
            "Epoch 7/87\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0367 - accuracy: 0.9895 - f1: 0.9894 - val_loss: 0.0970 - val_accuracy: 0.9735 - val_f1: 0.9735\n",
            "Epoch 8/87\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0289 - accuracy: 0.9911 - f1: 0.9910 - val_loss: 0.0971 - val_accuracy: 0.9756 - val_f1: 0.9760\n",
            "Epoch 9/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0237 - accuracy: 0.9933 - f1: 0.9933 - val_loss: 0.1027 - val_accuracy: 0.9736 - val_f1: 0.9738\n",
            "Epoch 10/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0189 - accuracy: 0.9946 - f1: 0.9946 - val_loss: 0.0995 - val_accuracy: 0.9772 - val_f1: 0.9774\n",
            "Epoch 11/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0161 - accuracy: 0.9956 - f1: 0.9956 - val_loss: 0.1183 - val_accuracy: 0.9707 - val_f1: 0.9709\n",
            "Epoch 12/87\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0139 - accuracy: 0.9962 - f1: 0.9963 - val_loss: 0.1023 - val_accuracy: 0.9772 - val_f1: 0.9775\n",
            "Epoch 13/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0117 - accuracy: 0.9970 - f1: 0.9969 - val_loss: 0.1081 - val_accuracy: 0.9771 - val_f1: 0.9774\n",
            "Epoch 14/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0102 - accuracy: 0.9970 - f1: 0.9970 - val_loss: 0.1371 - val_accuracy: 0.9722 - val_f1: 0.9724\n",
            "Epoch 15/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0081 - accuracy: 0.9981 - f1: 0.9980 - val_loss: 0.1200 - val_accuracy: 0.9767 - val_f1: 0.9766\n",
            "Epoch 16/87\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0084 - accuracy: 0.9978 - f1: 0.9978 - val_loss: 0.1254 - val_accuracy: 0.9754 - val_f1: 0.9754\n",
            "Epoch 17/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0074 - accuracy: 0.9984 - f1: 0.9984 - val_loss: 0.1241 - val_accuracy: 0.9778 - val_f1: 0.9777\n",
            "Epoch 18/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0062 - accuracy: 0.9987 - f1: 0.9987 - val_loss: 0.1312 - val_accuracy: 0.9770 - val_f1: 0.9773\n",
            "Epoch 19/87\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0065 - accuracy: 0.9984 - f1: 0.9984 - val_loss: 0.1362 - val_accuracy: 0.9757 - val_f1: 0.9759\n",
            "Epoch 20/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0061 - accuracy: 0.9987 - f1: 0.9987 - val_loss: 0.1274 - val_accuracy: 0.9783 - val_f1: 0.9783\n",
            "Epoch 21/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0064 - accuracy: 0.9984 - f1: 0.9984 - val_loss: 0.1361 - val_accuracy: 0.9767 - val_f1: 0.9767\n",
            "Epoch 22/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0055 - accuracy: 0.9990 - f1: 0.9990 - val_loss: 0.1437 - val_accuracy: 0.9773 - val_f1: 0.9776\n",
            "Epoch 23/87\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0056 - accuracy: 0.9990 - f1: 0.9990 - val_loss: 0.1385 - val_accuracy: 0.9782 - val_f1: 0.9784\n",
            "Epoch 24/87\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0048 - accuracy: 0.9991 - f1: 0.9991 - val_loss: 0.1462 - val_accuracy: 0.9780 - val_f1: 0.9782\n",
            "Epoch 25/87\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0051 - accuracy: 0.9989 - f1: 0.9989 - val_loss: 0.1420 - val_accuracy: 0.9773 - val_f1: 0.9775\n",
            "Epoch 26/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0056 - accuracy: 0.9988 - f1: 0.9988 - val_loss: 0.1350 - val_accuracy: 0.9789 - val_f1: 0.9791\n",
            "Epoch 27/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0046 - accuracy: 0.9991 - f1: 0.9991 - val_loss: 0.1462 - val_accuracy: 0.9776 - val_f1: 0.9777\n",
            "Epoch 28/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0049 - accuracy: 0.9991 - f1: 0.9991 - val_loss: 0.1566 - val_accuracy: 0.9780 - val_f1: 0.9781\n",
            "Epoch 29/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0050 - accuracy: 0.9990 - f1: 0.9990 - val_loss: 0.1581 - val_accuracy: 0.9770 - val_f1: 0.9769\n",
            "Epoch 30/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0053 - accuracy: 0.9988 - f1: 0.9988 - val_loss: 0.1588 - val_accuracy: 0.9776 - val_f1: 0.9774\n",
            "Epoch 31/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0038 - accuracy: 0.9993 - f1: 0.9993 - val_loss: 0.1480 - val_accuracy: 0.9793 - val_f1: 0.9796\n",
            "Epoch 32/87\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0045 - accuracy: 0.9993 - f1: 0.9993 - val_loss: 0.1622 - val_accuracy: 0.9767 - val_f1: 0.9766\n",
            "Epoch 33/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0046 - accuracy: 0.9993 - f1: 0.9993 - val_loss: 0.1916 - val_accuracy: 0.9735 - val_f1: 0.9738\n",
            "Epoch 34/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0036 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1618 - val_accuracy: 0.9772 - val_f1: 0.9776\n",
            "Epoch 35/87\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0047 - accuracy: 0.9992 - f1: 0.9993 - val_loss: 0.1583 - val_accuracy: 0.9793 - val_f1: 0.9794\n",
            "Epoch 36/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0037 - accuracy: 0.9995 - f1: 0.9994 - val_loss: 0.1739 - val_accuracy: 0.9773 - val_f1: 0.9772\n",
            "Epoch 37/87\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0043 - accuracy: 0.9991 - f1: 0.9991 - val_loss: 0.1727 - val_accuracy: 0.9783 - val_f1: 0.9786\n",
            "Epoch 38/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0040 - accuracy: 0.9992 - f1: 0.9993 - val_loss: 0.1504 - val_accuracy: 0.9793 - val_f1: 0.9794\n",
            "Epoch 39/87\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0045 - accuracy: 0.9992 - f1: 0.9992 - val_loss: 0.1619 - val_accuracy: 0.9786 - val_f1: 0.9788\n",
            "Epoch 40/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0042 - accuracy: 0.9993 - f1: 0.9993 - val_loss: 0.1638 - val_accuracy: 0.9808 - val_f1: 0.9810\n",
            "Epoch 41/87\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0044 - accuracy: 0.9992 - f1: 0.9993 - val_loss: 0.1695 - val_accuracy: 0.9784 - val_f1: 0.9786\n",
            "Epoch 42/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0042 - accuracy: 0.9993 - f1: 0.9993 - val_loss: 0.1705 - val_accuracy: 0.9789 - val_f1: 0.9791\n",
            "Epoch 43/87\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0036 - accuracy: 0.9994 - f1: 0.9994 - val_loss: 0.1612 - val_accuracy: 0.9785 - val_f1: 0.9784\n",
            "Epoch 44/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0040 - accuracy: 0.9992 - f1: 0.9992 - val_loss: 0.1602 - val_accuracy: 0.9797 - val_f1: 0.9797\n",
            "Epoch 45/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0039 - accuracy: 0.9992 - f1: 0.9992 - val_loss: 0.1706 - val_accuracy: 0.9783 - val_f1: 0.9784\n",
            "Epoch 46/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0038 - accuracy: 0.9994 - f1: 0.9994 - val_loss: 0.1485 - val_accuracy: 0.9800 - val_f1: 0.9799\n",
            "Epoch 47/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0040 - accuracy: 0.9994 - f1: 0.9994 - val_loss: 0.1672 - val_accuracy: 0.9793 - val_f1: 0.9792\n",
            "Epoch 48/87\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0038 - accuracy: 0.9993 - f1: 0.9993 - val_loss: 0.1708 - val_accuracy: 0.9786 - val_f1: 0.9787\n",
            "Epoch 49/87\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0036 - accuracy: 0.9994 - f1: 0.9994 - val_loss: 0.1594 - val_accuracy: 0.9789 - val_f1: 0.9791\n",
            "Epoch 50/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0039 - accuracy: 0.9994 - f1: 0.9994 - val_loss: 0.1605 - val_accuracy: 0.9800 - val_f1: 0.9801\n",
            "Epoch 51/87\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0041 - accuracy: 0.9992 - f1: 0.9992 - val_loss: 0.1621 - val_accuracy: 0.9805 - val_f1: 0.9806\n",
            "Epoch 52/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0039 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1867 - val_accuracy: 0.9744 - val_f1: 0.9744\n",
            "Epoch 53/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0044 - accuracy: 0.9991 - f1: 0.9991 - val_loss: 0.1620 - val_accuracy: 0.9800 - val_f1: 0.9801\n",
            "Epoch 54/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0039 - accuracy: 0.9992 - f1: 0.9992 - val_loss: 0.1540 - val_accuracy: 0.9805 - val_f1: 0.9807\n",
            "Epoch 55/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0039 - accuracy: 0.9994 - f1: 0.9994 - val_loss: 0.1841 - val_accuracy: 0.9762 - val_f1: 0.9765\n",
            "Epoch 56/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0042 - accuracy: 0.9993 - f1: 0.9993 - val_loss: 0.1543 - val_accuracy: 0.9801 - val_f1: 0.9802\n",
            "Epoch 57/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0034 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1607 - val_accuracy: 0.9797 - val_f1: 0.9798\n",
            "Epoch 58/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0031 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1738 - val_accuracy: 0.9790 - val_f1: 0.9791\n",
            "Epoch 59/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0032 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1796 - val_accuracy: 0.9778 - val_f1: 0.9777\n",
            "Epoch 60/87\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0045 - accuracy: 0.9993 - f1: 0.9993 - val_loss: 0.1692 - val_accuracy: 0.9788 - val_f1: 0.9791\n",
            "Epoch 61/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0036 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1670 - val_accuracy: 0.9804 - val_f1: 0.9804\n",
            "Epoch 62/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0033 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1770 - val_accuracy: 0.9789 - val_f1: 0.9790\n",
            "Epoch 63/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0029 - accuracy: 0.9997 - f1: 0.9997 - val_loss: 0.1699 - val_accuracy: 0.9801 - val_f1: 0.9800\n",
            "Epoch 64/87\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0037 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1723 - val_accuracy: 0.9796 - val_f1: 0.9798\n",
            "Epoch 65/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0034 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1640 - val_accuracy: 0.9799 - val_f1: 0.9799\n",
            "Epoch 66/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0038 - accuracy: 0.9994 - f1: 0.9994 - val_loss: 0.1693 - val_accuracy: 0.9789 - val_f1: 0.9791\n",
            "Epoch 67/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0036 - accuracy: 0.9994 - f1: 0.9994 - val_loss: 0.1760 - val_accuracy: 0.9776 - val_f1: 0.9776\n",
            "Epoch 68/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0036 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1684 - val_accuracy: 0.9781 - val_f1: 0.9780\n",
            "Epoch 69/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0033 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1754 - val_accuracy: 0.9783 - val_f1: 0.9783\n",
            "Epoch 70/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0041 - accuracy: 0.9992 - f1: 0.9992 - val_loss: 0.1815 - val_accuracy: 0.9778 - val_f1: 0.9779\n",
            "Epoch 71/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0038 - accuracy: 0.9994 - f1: 0.9994 - val_loss: 0.2101 - val_accuracy: 0.9757 - val_f1: 0.9758\n",
            "Epoch 72/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0042 - accuracy: 0.9993 - f1: 0.9993 - val_loss: 0.1717 - val_accuracy: 0.9793 - val_f1: 0.9793\n",
            "Epoch 73/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0039 - accuracy: 0.9993 - f1: 0.9993 - val_loss: 0.1607 - val_accuracy: 0.9808 - val_f1: 0.9808\n",
            "Epoch 74/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0031 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1685 - val_accuracy: 0.9783 - val_f1: 0.9783\n",
            "Epoch 75/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0034 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1702 - val_accuracy: 0.9788 - val_f1: 0.9789\n",
            "Epoch 76/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0035 - accuracy: 0.9994 - f1: 0.9993 - val_loss: 0.1566 - val_accuracy: 0.9808 - val_f1: 0.9808\n",
            "Epoch 77/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0030 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1655 - val_accuracy: 0.9800 - val_f1: 0.9800\n",
            "Epoch 78/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0033 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1788 - val_accuracy: 0.9765 - val_f1: 0.9766\n",
            "Epoch 79/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0038 - accuracy: 0.9993 - f1: 0.9993 - val_loss: 0.1750 - val_accuracy: 0.9787 - val_f1: 0.9787\n",
            "Epoch 80/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0031 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.1704 - val_accuracy: 0.9797 - val_f1: 0.9799\n",
            "Epoch 81/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0025 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1632 - val_accuracy: 0.9790 - val_f1: 0.9791\n",
            "Epoch 82/87\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.0030 - accuracy: 0.9995 - f1: 0.9995 - val_loss: 0.2021 - val_accuracy: 0.9768 - val_f1: 0.9768\n",
            "Epoch 83/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0028 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1642 - val_accuracy: 0.9798 - val_f1: 0.9799\n",
            "Epoch 84/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0029 - accuracy: 0.9996 - f1: 0.9996 - val_loss: 0.1639 - val_accuracy: 0.9800 - val_f1: 0.9800\n",
            "Epoch 85/87\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0033 - accuracy: 0.9994 - f1: 0.9994 - val_loss: 0.1609 - val_accuracy: 0.9794 - val_f1: 0.9795\n",
            "Epoch 86/87\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0038 - accuracy: 0.9994 - f1: 0.9994 - val_loss: 0.1569 - val_accuracy: 0.9809 - val_f1: 0.9810\n",
            "Epoch 87/87\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0030 - accuracy: 0.9995 - f1: 0.9996 - val_loss: 0.1897 - val_accuracy: 0.9770 - val_f1: 0.9773\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f262013e2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation of model in unseen test data set\n",
        "ypred = hypermodel.predict(Xtest) # Predictions of best model on unseen test set\n",
        "conf_matrix = confusion_matrix(ytest, ypred.argmax(axis=1)) # ypred needs to be in the same form as ytest : 1d array with class predictions\n",
        "classes = ['0', '1','2','3','4','5','6','7','8','9']\n",
        "df_conf_matrix = pd.DataFrame(conf_matrix, classes,classes)\n",
        "print(\"Classification report:\\n\",classification_report(ytest, ypred.argmax(axis=1), target_names=classes))\n",
        "print(\"Confusion matrix where rows are true labels and columns are predicted classes: \\n\")\n",
        "df_conf_matrix\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        },
        "id": "QwRF7vd8sIfy",
        "outputId": "02dcfdf0-a2bf-4949-cda9-8c537b4c315c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99       980\n",
            "           1       0.99      1.00      0.99      1135\n",
            "           2       0.98      0.98      0.98      1032\n",
            "           3       0.99      0.97      0.98      1010\n",
            "           4       0.97      0.97      0.97       982\n",
            "           5       0.99      0.97      0.98       892\n",
            "           6       0.98      0.98      0.98       958\n",
            "           7       0.97      0.97      0.97      1028\n",
            "           8       0.98      0.97      0.98       974\n",
            "           9       0.95      0.99      0.97      1009\n",
            "\n",
            "    accuracy                           0.98     10000\n",
            "   macro avg       0.98      0.98      0.98     10000\n",
            "weighted avg       0.98      0.98      0.98     10000\n",
            "\n",
            "Confusion matrix where rows are true labels and columns are predicted classes: \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     0     1     2    3    4    5    6     7    8    9\n",
              "0  970     1     1    0    0    0    4     0    1    3\n",
              "1    0  1130     1    0    0    1    1     1    1    0\n",
              "2    1     1  1013    2    3    0    1     7    4    0\n",
              "3    3     3     6  976    0    5    0     6    1   10\n",
              "4    1     1     1    1  953    0    4     3    2   16\n",
              "5    4     0     0    3    2  864    8     3    4    4\n",
              "6    4     2     1    1   10    1  939     0    0    0\n",
              "7    1     2    11    1    2    0    0  1000    2    9\n",
              "8    3     1     2    4    5    2    2     4  946    5\n",
              "9    2     4     0    1    4    0    1     3    0  994"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-07f22efe-1ad8-44b1-9426-0835cb4c34a1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>970</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1130</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1013</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>976</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>953</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>864</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>939</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1000</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>946</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>994</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07f22efe-1ad8-44b1-9426-0835cb4c34a1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-07f22efe-1ad8-44b1-9426-0835cb4c34a1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-07f22efe-1ad8-44b1-9426-0835cb4c34a1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    }
  ]
}